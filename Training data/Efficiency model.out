wandb: Currently logged in as: r-v-doorn1 (royvdoorn). Use `wandb login --relogin` to force relogin
/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.
  warnings.warn(
Loss of batch at epoch 1 : 3.072387933731079
Loss of batch at epoch 1 : 2.9104530811309814
Loss of batch at epoch 1 : 2.8480331897735596
Loss of batch at epoch 1 : 2.7402329444885254
Loss of batch at epoch 1 : 2.6571168899536133
Loss of batch at epoch 1 : 2.5930209159851074
Loss of batch at epoch 1 : 2.582427978515625
Loss of batch at epoch 1 : 2.543776035308838
Loss of batch at epoch 1 : 2.4344935417175293
Loss of batch at epoch 1 : 2.3973381519317627
Loss of batch at epoch 1 : 2.346121072769165
Loss of batch at epoch 1 : 2.319024085998535
Loss of batch at epoch 1 : 2.3379812240600586
Loss of batch at epoch 1 : 2.2479324340820312
Loss of batch at epoch 1 : 2.1581830978393555
Loss of batch at epoch 1 : 2.1823136806488037
Loss of batch at epoch 1 : 2.1061012744903564
Loss of batch at epoch 1 : 2.0398707389831543
Loss of batch at epoch 1 : 1.988050103187561
Loss of batch at epoch 1 : 1.9323811531066895
Loss of batch at epoch 1 : 1.947220802307129
Loss of batch at epoch 1 : 1.9674931764602661
Loss of batch at epoch 1 : 1.838473916053772
Loss of batch at epoch 1 : 1.8944557905197144
Loss of batch at epoch 1 : 1.7744157314300537
Loss of batch at epoch 1 : 1.7582899332046509
Loss of batch at epoch 1 : 1.7182257175445557
Loss of batch at epoch 1 : 1.7309222221374512
Loss of batch at epoch 1 : 1.7090768814086914
Loss of batch at epoch 1 : 1.6624085903167725
Loss of batch at epoch 1 : 1.6724236011505127
Loss of batch at epoch 1 : 1.6509310007095337
Loss of batch at epoch 1 : 1.5801810026168823
Loss of batch at epoch 1 : 1.5530542135238647
Loss of batch at epoch 1 : 1.5335729122161865
Loss of batch at epoch 1 : 1.5259085893630981
Loss of batch at epoch 1 : 1.5563149452209473
Loss of batch at epoch 1 : 1.5367059707641602
Loss of batch at epoch 1 : 1.5117738246917725
Loss of batch at epoch 1 : 1.4957082271575928
Loss of batch at epoch 1 : 1.4507066011428833
Loss of batch at epoch 1 : 1.4460052251815796
Loss of batch at epoch 1 : 1.5401768684387207
Loss of batch at epoch 1 : 1.4242366552352905
Loss of batch at epoch 1 : 1.4587812423706055
Loss of batch at epoch 1 : 1.3820322751998901
Loss of batch at epoch 1 : 1.4688982963562012
Loss of batch at epoch 1 : 1.3977919816970825
Loss of batch at epoch 1 : 1.3832643032073975
Loss of batch at epoch 1 : 1.3832142353057861
Loss of batch at epoch 1 : 1.5150644779205322
Loss of batch at epoch 1 : 1.385655164718628
Loss of batch at epoch 1 : 1.325549602508545
Loss of batch at epoch 1 : 1.3989295959472656
Average train loss of epoch 1: 0.03809376062075535
Average validation loss of epoch 1: 0.027557180385396937
Loss of batch at epoch 2 : 1.3417195081710815
Loss of batch at epoch 2 : 1.3983988761901855
Loss of batch at epoch 2 : 1.377234935760498
Loss of batch at epoch 2 : 1.30202317237854
Loss of batch at epoch 2 : 1.3533657789230347
Loss of batch at epoch 2 : 1.2806750535964966
Loss of batch at epoch 2 : 1.2846394777297974
Loss of batch at epoch 2 : 1.2414482831954956
Loss of batch at epoch 2 : 1.26983642578125
Loss of batch at epoch 2 : 1.2345798015594482
Loss of batch at epoch 2 : 1.3645734786987305
Loss of batch at epoch 2 : 1.2733358144760132
Loss of batch at epoch 2 : 1.22837495803833
Loss of batch at epoch 2 : 1.2078958749771118
Loss of batch at epoch 2 : 1.263911247253418
Loss of batch at epoch 2 : 1.1936975717544556
Loss of batch at epoch 2 : 1.272528052330017
Loss of batch at epoch 2 : 1.2439167499542236
Loss of batch at epoch 2 : 1.2459789514541626
Loss of batch at epoch 2 : 1.2231776714324951
Loss of batch at epoch 2 : 1.1755836009979248
Loss of batch at epoch 2 : 1.1924067735671997
Loss of batch at epoch 2 : 1.2111512422561646
Loss of batch at epoch 2 : 1.2282887697219849
Loss of batch at epoch 2 : 1.1484389305114746
Loss of batch at epoch 2 : 1.1329069137573242
Loss of batch at epoch 2 : 1.196906566619873
Loss of batch at epoch 2 : 1.1583342552185059
Loss of batch at epoch 2 : 1.0980737209320068
Loss of batch at epoch 2 : 1.139992594718933
Loss of batch at epoch 2 : 1.1467463970184326
Loss of batch at epoch 2 : 1.1541674137115479
Loss of batch at epoch 2 : 1.0714534521102905
Loss of batch at epoch 2 : 1.1077792644500732
Loss of batch at epoch 2 : 1.1243274211883545
Loss of batch at epoch 2 : 1.1174687147140503
Loss of batch at epoch 2 : 1.1362125873565674
Loss of batch at epoch 2 : 1.0917352437973022
Loss of batch at epoch 2 : 1.1518678665161133
Loss of batch at epoch 2 : 1.1406190395355225
Loss of batch at epoch 2 : 1.049049973487854
Loss of batch at epoch 2 : 1.0931015014648438
Loss of batch at epoch 2 : 1.1334750652313232
Loss of batch at epoch 2 : 1.1303387880325317
Loss of batch at epoch 2 : 1.0946561098098755
Loss of batch at epoch 2 : 1.0663288831710815
Loss of batch at epoch 2 : 1.0672776699066162
Loss of batch at epoch 2 : 1.0777889490127563
Loss of batch at epoch 2 : 1.1094985008239746
Loss of batch at epoch 2 : 1.0748438835144043
Loss of batch at epoch 2 : 1.062825322151184
Loss of batch at epoch 2 : 1.0898929834365845
Loss of batch at epoch 2 : 1.052097201347351
Loss of batch at epoch 2 : 1.0402969121932983
Average train loss of epoch 2: 0.023774176235070773
Average validation loss of epoch 2: 0.02143471329300492
Loss of batch at epoch 3 : 1.0715078115463257
Loss of batch at epoch 3 : 1.029512882232666
Loss of batch at epoch 3 : 1.0555777549743652
Loss of batch at epoch 3 : 1.0538278818130493
Loss of batch at epoch 3 : 1.0093753337860107
Loss of batch at epoch 3 : 1.0049571990966797
Loss of batch at epoch 3 : 1.0935943126678467
Loss of batch at epoch 3 : 1.0051928758621216
Loss of batch at epoch 3 : 1.0481524467468262
Loss of batch at epoch 3 : 1.0459638833999634
Loss of batch at epoch 3 : 1.1124629974365234
Loss of batch at epoch 3 : 1.011901617050171
Loss of batch at epoch 3 : 1.0053049325942993
Loss of batch at epoch 3 : 1.0079106092453003
Loss of batch at epoch 3 : 1.007156252861023
Loss of batch at epoch 3 : 0.9675809144973755
Loss of batch at epoch 3 : 1.0065170526504517
Loss of batch at epoch 3 : 1.0335593223571777
Loss of batch at epoch 3 : 0.9950072765350342
Loss of batch at epoch 3 : 1.0135656595230103
Loss of batch at epoch 3 : 1.022346019744873
Loss of batch at epoch 3 : 1.0033936500549316
Loss of batch at epoch 3 : 0.9844797849655151
Loss of batch at epoch 3 : 1.0204086303710938
Loss of batch at epoch 3 : 0.9626821875572205
Loss of batch at epoch 3 : 0.9952499270439148
Loss of batch at epoch 3 : 0.9119324088096619
Loss of batch at epoch 3 : 0.963005781173706
Loss of batch at epoch 3 : 0.998498797416687
Loss of batch at epoch 3 : 1.0050740242004395
Loss of batch at epoch 3 : 0.9730186462402344
Loss of batch at epoch 3 : 0.9426152110099792
Loss of batch at epoch 3 : 0.9309507012367249
Loss of batch at epoch 3 : 0.9371999502182007
Loss of batch at epoch 3 : 0.9727783799171448
Loss of batch at epoch 3 : 0.9771603345870972
Loss of batch at epoch 3 : 0.9472827315330505
Loss of batch at epoch 3 : 0.9760457873344421
Loss of batch at epoch 3 : 0.8915615677833557
Loss of batch at epoch 3 : 0.9667955636978149
Loss of batch at epoch 3 : 0.9508550763130188
Loss of batch at epoch 3 : 0.9674972891807556
Loss of batch at epoch 3 : 0.9503806233406067
Loss of batch at epoch 3 : 0.9282523989677429
Loss of batch at epoch 3 : 0.9320704340934753
Loss of batch at epoch 3 : 0.9306729435920715
Loss of batch at epoch 3 : 0.9683679938316345
Loss of batch at epoch 3 : 0.9552636742591858
Loss of batch at epoch 3 : 0.9291595220565796
Loss of batch at epoch 3 : 0.9257953763008118
Loss of batch at epoch 3 : 0.8313931822776794
Loss of batch at epoch 3 : 0.8731452226638794
Loss of batch at epoch 3 : 0.9373947381973267
Loss of batch at epoch 3 : 1.0314244031906128
Average train loss of epoch 3: 0.01981807164597458
Average validation loss of epoch 3: 0.018583150022359007
Loss of batch at epoch 4 : 0.8883167505264282
Loss of batch at epoch 4 : 0.9441430568695068
Loss of batch at epoch 4 : 0.9078359007835388
Loss of batch at epoch 4 : 0.8789523243904114
Loss of batch at epoch 4 : 0.9621897339820862
Loss of batch at epoch 4 : 0.8901561498641968
Loss of batch at epoch 4 : 0.879190981388092
Loss of batch at epoch 4 : 0.8810118436813354
Loss of batch at epoch 4 : 0.9406054019927979
Loss of batch at epoch 4 : 0.9664470553398132
Loss of batch at epoch 4 : 0.9123262763023376
Loss of batch at epoch 4 : 0.8667635917663574
Loss of batch at epoch 4 : 0.9035996794700623
Loss of batch at epoch 4 : 0.8997421264648438
Loss of batch at epoch 4 : 0.8207440376281738
Loss of batch at epoch 4 : 0.8681172132492065
Loss of batch at epoch 4 : 0.8639523983001709
Loss of batch at epoch 4 : 0.8835678100585938
Loss of batch at epoch 4 : 0.9298650622367859
Loss of batch at epoch 4 : 0.8651914596557617
Loss of batch at epoch 4 : 0.8646087050437927
Loss of batch at epoch 4 : 0.8428842425346375
Loss of batch at epoch 4 : 0.8323646187782288
Loss of batch at epoch 4 : 0.8962454795837402
Loss of batch at epoch 4 : 0.911679744720459
Loss of batch at epoch 4 : 0.849900484085083
Loss of batch at epoch 4 : 0.8595531582832336
Loss of batch at epoch 4 : 0.8268300890922546
Loss of batch at epoch 4 : 0.8447508215904236
Loss of batch at epoch 4 : 0.9089730381965637
Loss of batch at epoch 4 : 0.8549180030822754
Loss of batch at epoch 4 : 0.8156982660293579
Loss of batch at epoch 4 : 0.8798340559005737
Loss of batch at epoch 4 : 0.8479880094528198
Loss of batch at epoch 4 : 0.8359721899032593
Loss of batch at epoch 4 : 0.8496542572975159
Loss of batch at epoch 4 : 0.9300030469894409
Loss of batch at epoch 4 : 0.8156566023826599
Loss of batch at epoch 4 : 0.9231734871864319
Loss of batch at epoch 4 : 0.802935779094696
Loss of batch at epoch 4 : 0.8593384623527527
Loss of batch at epoch 4 : 0.8113515973091125
Loss of batch at epoch 4 : 0.9080654382705688
Loss of batch at epoch 4 : 0.8184458613395691
Loss of batch at epoch 4 : 0.8013423681259155
Loss of batch at epoch 4 : 0.871904194355011
Loss of batch at epoch 4 : 0.8514394164085388
Loss of batch at epoch 4 : 0.8390133380889893
Loss of batch at epoch 4 : 0.877700924873352
Loss of batch at epoch 4 : 0.8281108140945435
Loss of batch at epoch 4 : 0.8203862905502319
Loss of batch at epoch 4 : 0.7997457981109619
Loss of batch at epoch 4 : 0.8968570232391357
Loss of batch at epoch 4 : 0.9311420321464539
Average train loss of epoch 4: 0.017573256204162096
Average validation loss of epoch 4: 0.01693459391995311
Loss of batch at epoch 5 : 0.8487626314163208
Loss of batch at epoch 5 : 0.7910327911376953
Loss of batch at epoch 5 : 0.7853929996490479
Loss of batch at epoch 5 : 0.8788663148880005
Loss of batch at epoch 5 : 0.8171115517616272
Loss of batch at epoch 5 : 0.775061309337616
Loss of batch at epoch 5 : 0.7969065308570862
Loss of batch at epoch 5 : 0.8348002433776855
Loss of batch at epoch 5 : 0.7495049238204956
Loss of batch at epoch 5 : 0.8114872574806213
Loss of batch at epoch 5 : 0.8344706296920776
Loss of batch at epoch 5 : 0.7697108387947083
Loss of batch at epoch 5 : 0.8094950914382935
Loss of batch at epoch 5 : 0.7533665299415588
Loss of batch at epoch 5 : 0.7904022336006165
Loss of batch at epoch 5 : 0.7837947010993958
Loss of batch at epoch 5 : 0.7831205725669861
Loss of batch at epoch 5 : 0.8297950625419617
Loss of batch at epoch 5 : 0.7903674840927124
Loss of batch at epoch 5 : 0.851209282875061
Loss of batch at epoch 5 : 0.8535069227218628
Loss of batch at epoch 5 : 0.8605570793151855
Loss of batch at epoch 5 : 0.7604609727859497
Loss of batch at epoch 5 : 0.7626932263374329
Loss of batch at epoch 5 : 0.770484209060669
Loss of batch at epoch 5 : 0.7712476849555969
Loss of batch at epoch 5 : 0.7434185147285461
Loss of batch at epoch 5 : 0.7920034527778625
Loss of batch at epoch 5 : 0.8136399984359741
Loss of batch at epoch 5 : 0.7237098813056946
Loss of batch at epoch 5 : 0.7871460914611816
Loss of batch at epoch 5 : 0.8212468028068542
Loss of batch at epoch 5 : 0.7330878973007202
Loss of batch at epoch 5 : 0.7511555552482605
Loss of batch at epoch 5 : 0.7559278011322021
Loss of batch at epoch 5 : 0.8110023140907288
Loss of batch at epoch 5 : 0.8206022381782532
Loss of batch at epoch 5 : 0.9063557386398315
Loss of batch at epoch 5 : 0.7513177990913391
Loss of batch at epoch 5 : 0.838310718536377
Loss of batch at epoch 5 : 0.7631810307502747
Loss of batch at epoch 5 : 0.8292104601860046
Loss of batch at epoch 5 : 0.8332372903823853
Loss of batch at epoch 5 : 0.763218343257904
Loss of batch at epoch 5 : 0.8105514645576477
Loss of batch at epoch 5 : 0.8455601930618286
Loss of batch at epoch 5 : 0.8306147456169128
Loss of batch at epoch 5 : 0.7619193196296692
Loss of batch at epoch 5 : 0.7459599375724792
Loss of batch at epoch 5 : 0.8116687536239624
Loss of batch at epoch 5 : 0.7785829901695251
Loss of batch at epoch 5 : 0.8067560791969299
Loss of batch at epoch 5 : 0.8609363436698914
Loss of batch at epoch 5 : 0.7537350654602051
Average train loss of epoch 5: 0.0160969626645351
Average validation loss of epoch 5: 0.016056990382647275
Loss of batch at epoch 6 : 0.7466773986816406
Loss of batch at epoch 6 : 0.7271512150764465
Loss of batch at epoch 6 : 0.7736154198646545
Loss of batch at epoch 6 : 0.7475370168685913
Loss of batch at epoch 6 : 0.7148299217224121
Loss of batch at epoch 6 : 0.7485454082489014
Loss of batch at epoch 6 : 0.7541486620903015
Loss of batch at epoch 6 : 0.7508203387260437
Loss of batch at epoch 6 : 0.7532421946525574
Loss of batch at epoch 6 : 0.722241222858429
Loss of batch at epoch 6 : 0.8612273931503296
Loss of batch at epoch 6 : 0.8559381365776062
Loss of batch at epoch 6 : 0.8254777789115906
Loss of batch at epoch 6 : 0.7089059948921204
Loss of batch at epoch 6 : 0.733945369720459
Loss of batch at epoch 6 : 0.8020985722541809
Loss of batch at epoch 6 : 0.8386390209197998
Loss of batch at epoch 6 : 0.7748808264732361
Loss of batch at epoch 6 : 0.790118396282196
Loss of batch at epoch 6 : 0.7199572920799255
Loss of batch at epoch 6 : 0.7331675887107849
Loss of batch at epoch 6 : 0.707555890083313
Loss of batch at epoch 6 : 0.7419759035110474
Loss of batch at epoch 6 : 0.7999441027641296
Loss of batch at epoch 6 : 0.7460349202156067
Loss of batch at epoch 6 : 0.7438144683837891
Loss of batch at epoch 6 : 0.7241702079772949
Loss of batch at epoch 6 : 0.7435394525527954
Loss of batch at epoch 6 : 0.7990220785140991
Loss of batch at epoch 6 : 0.7304895520210266
Loss of batch at epoch 6 : 0.7190672755241394
Loss of batch at epoch 6 : 0.8125697374343872
Loss of batch at epoch 6 : 0.7453139424324036
Loss of batch at epoch 6 : 0.7764570116996765
Loss of batch at epoch 6 : 0.7445157766342163
Loss of batch at epoch 6 : 0.7328432202339172
Loss of batch at epoch 6 : 0.7449788451194763
Loss of batch at epoch 6 : 0.6903952956199646
Loss of batch at epoch 6 : 0.6858729124069214
Loss of batch at epoch 6 : 0.7480543255805969
Loss of batch at epoch 6 : 0.7473948001861572
Loss of batch at epoch 6 : 0.7206593751907349
Loss of batch at epoch 6 : 0.7056677341461182
Loss of batch at epoch 6 : 0.7448017001152039
Loss of batch at epoch 6 : 0.7990739941596985
Loss of batch at epoch 6 : 0.7205255627632141
Loss of batch at epoch 6 : 0.7445209622383118
Loss of batch at epoch 6 : 0.7181854844093323
Loss of batch at epoch 6 : 0.7156022191047668
Loss of batch at epoch 6 : 0.7018260359764099
Loss of batch at epoch 6 : 0.7039851546287537
Loss of batch at epoch 6 : 0.689364492893219
Loss of batch at epoch 6 : 0.7535442113876343
Loss of batch at epoch 6 : 0.6985964775085449
Average train loss of epoch 6: 0.015079731902050562
Average validation loss of epoch 6: 0.014844422388558437
Loss of batch at epoch 7 : 0.6748520135879517
Loss of batch at epoch 7 : 0.7583969235420227
Loss of batch at epoch 7 : 0.7234618067741394
Loss of batch at epoch 7 : 0.7495577335357666
Loss of batch at epoch 7 : 0.6875259280204773
Loss of batch at epoch 7 : 0.6974732279777527
Loss of batch at epoch 7 : 0.7307788729667664
Loss of batch at epoch 7 : 0.6688053011894226
Loss of batch at epoch 7 : 0.7049098014831543
Loss of batch at epoch 7 : 0.680694043636322
Loss of batch at epoch 7 : 0.7249109745025635
Loss of batch at epoch 7 : 0.718572199344635
Loss of batch at epoch 7 : 0.7363552451133728
Loss of batch at epoch 7 : 0.715156614780426
Loss of batch at epoch 7 : 0.7752617597579956
Loss of batch at epoch 7 : 0.7033432722091675
Loss of batch at epoch 7 : 0.6890574097633362
Loss of batch at epoch 7 : 0.7317535281181335
Loss of batch at epoch 7 : 0.7850468754768372
Loss of batch at epoch 7 : 0.6255605816841125
Loss of batch at epoch 7 : 0.6482762694358826
Loss of batch at epoch 7 : 0.671796977519989
Loss of batch at epoch 7 : 0.7145341634750366
Loss of batch at epoch 7 : 0.6855877637863159
Loss of batch at epoch 7 : 0.7766942977905273
Loss of batch at epoch 7 : 0.7500225901603699
Loss of batch at epoch 7 : 0.6863642334938049
Loss of batch at epoch 7 : 0.7015410661697388
Loss of batch at epoch 7 : 0.738911509513855
Loss of batch at epoch 7 : 0.7334381341934204
Loss of batch at epoch 7 : 0.718268096446991
Loss of batch at epoch 7 : 0.6578883528709412
Loss of batch at epoch 7 : 0.6585938930511475
Loss of batch at epoch 7 : 0.6499131917953491
Loss of batch at epoch 7 : 0.6993080377578735
Loss of batch at epoch 7 : 0.7197924256324768
Loss of batch at epoch 7 : 0.6665791869163513
Loss of batch at epoch 7 : 0.6682133674621582
Loss of batch at epoch 7 : 0.8068327307701111
Loss of batch at epoch 7 : 0.7342260479927063
Loss of batch at epoch 7 : 0.7583475708961487
Loss of batch at epoch 7 : 0.6499360203742981
Loss of batch at epoch 7 : 0.7267865538597107
Loss of batch at epoch 7 : 0.6759580969810486
Loss of batch at epoch 7 : 0.7285765409469604
Loss of batch at epoch 7 : 0.6871852278709412
Loss of batch at epoch 7 : 0.6600914001464844
Loss of batch at epoch 7 : 0.6953575611114502
Loss of batch at epoch 7 : 0.6988366842269897
Loss of batch at epoch 7 : 0.7543194890022278
Loss of batch at epoch 7 : 0.7120752930641174
Loss of batch at epoch 7 : 0.6664973497390747
Loss of batch at epoch 7 : 0.6749876141548157
Loss of batch at epoch 7 : 0.6664639115333557
Average train loss of epoch 7: 0.014235876138927867
Average validation loss of epoch 7: 0.0141622867648449
Loss of batch at epoch 8 : 0.6779639720916748
Loss of batch at epoch 8 : 0.6812246441841125
Loss of batch at epoch 8 : 0.6688356399536133
Loss of batch at epoch 8 : 0.6800169944763184
Loss of batch at epoch 8 : 0.6584363579750061
Loss of batch at epoch 8 : 0.7295740246772766
Loss of batch at epoch 8 : 0.6958751082420349
Loss of batch at epoch 8 : 0.6467359066009521
Loss of batch at epoch 8 : 0.6313787698745728
Loss of batch at epoch 8 : 0.6546664834022522
Loss of batch at epoch 8 : 0.6339412927627563
Loss of batch at epoch 8 : 0.6532277464866638
Loss of batch at epoch 8 : 0.6653161644935608
Loss of batch at epoch 8 : 0.6339669823646545
Loss of batch at epoch 8 : 0.6624994277954102
Loss of batch at epoch 8 : 0.6753467917442322
Loss of batch at epoch 8 : 0.6648831963539124
Loss of batch at epoch 8 : 0.7402737140655518
Loss of batch at epoch 8 : 0.7526293992996216
Loss of batch at epoch 8 : 0.7108237147331238
Loss of batch at epoch 8 : 0.7128838300704956
Loss of batch at epoch 8 : 0.618787407875061
Loss of batch at epoch 8 : 0.6373330354690552
Loss of batch at epoch 8 : 0.6976354718208313
Loss of batch at epoch 8 : 0.6688363552093506
Loss of batch at epoch 8 : 0.717761754989624
Loss of batch at epoch 8 : 0.6844931244850159
Loss of batch at epoch 8 : 0.6130671501159668
Loss of batch at epoch 8 : 0.7049882411956787
Loss of batch at epoch 8 : 0.6296124458312988
Loss of batch at epoch 8 : 0.6763291954994202
Loss of batch at epoch 8 : 0.6408970355987549
Loss of batch at epoch 8 : 0.6792802214622498
Loss of batch at epoch 8 : 0.6559060215950012
Loss of batch at epoch 8 : 0.659755289554596
Loss of batch at epoch 8 : 0.6604364514350891
Loss of batch at epoch 8 : 0.7051340341567993
Loss of batch at epoch 8 : 0.6484127044677734
Loss of batch at epoch 8 : 0.6582848429679871
Loss of batch at epoch 8 : 0.6521010994911194
Loss of batch at epoch 8 : 0.6343677639961243
Loss of batch at epoch 8 : 0.681549608707428
Loss of batch at epoch 8 : 0.6727467775344849
Loss of batch at epoch 8 : 0.6763777136802673
Loss of batch at epoch 8 : 0.6927825212478638
Loss of batch at epoch 8 : 0.6721773743629456
Loss of batch at epoch 8 : 0.71957927942276
Loss of batch at epoch 8 : 0.7115186452865601
Loss of batch at epoch 8 : 0.6402424573898315
Loss of batch at epoch 8 : 0.7083153128623962
Loss of batch at epoch 8 : 0.5973847508430481
Loss of batch at epoch 8 : 0.6838803887367249
Loss of batch at epoch 8 : 0.6107714176177979
Loss of batch at epoch 8 : 0.6639792919158936
Average train loss of epoch 8: 0.013519503626919576
Average validation loss of epoch 8: 0.013592784252230969
Loss of batch at epoch 9 : 0.6640135645866394
Loss of batch at epoch 9 : 0.6243951320648193
Loss of batch at epoch 9 : 0.6014277935028076
Loss of batch at epoch 9 : 0.6572646498680115
Loss of batch at epoch 9 : 0.6764570474624634
Loss of batch at epoch 9 : 0.6396042704582214
Loss of batch at epoch 9 : 0.6761455535888672
Loss of batch at epoch 9 : 0.6524390578269958
Loss of batch at epoch 9 : 0.6701198220252991
Loss of batch at epoch 9 : 0.5930854082107544
Loss of batch at epoch 9 : 0.643263578414917
Loss of batch at epoch 9 : 0.6887871623039246
Loss of batch at epoch 9 : 0.6750303506851196
Loss of batch at epoch 9 : 0.6710012555122375
Loss of batch at epoch 9 : 0.6500822305679321
Loss of batch at epoch 9 : 0.6335194110870361
Loss of batch at epoch 9 : 0.6142538189888
Loss of batch at epoch 9 : 0.6423842906951904
Loss of batch at epoch 9 : 0.629900336265564
Loss of batch at epoch 9 : 0.6435590386390686
Loss of batch at epoch 9 : 0.6754606366157532
Loss of batch at epoch 9 : 0.632285475730896
Loss of batch at epoch 9 : 0.654351532459259
Loss of batch at epoch 9 : 0.6531569361686707
Loss of batch at epoch 9 : 0.6895526051521301
Loss of batch at epoch 9 : 0.5919337272644043
Loss of batch at epoch 9 : 0.6851008534431458
Loss of batch at epoch 9 : 0.6214918494224548
Loss of batch at epoch 9 : 0.6072308421134949
Loss of batch at epoch 9 : 0.6617094874382019
Loss of batch at epoch 9 : 0.7154511213302612
Loss of batch at epoch 9 : 0.6352841854095459
Loss of batch at epoch 9 : 0.6380944848060608
Loss of batch at epoch 9 : 0.6680676341056824
Loss of batch at epoch 9 : 0.655137300491333
Loss of batch at epoch 9 : 0.6134015321731567
Loss of batch at epoch 9 : 0.6037498116493225
Loss of batch at epoch 9 : 0.6067134141921997
Loss of batch at epoch 9 : 0.6819428205490112
Loss of batch at epoch 9 : 0.6531960368156433
Loss of batch at epoch 9 : 0.6566463708877563
Loss of batch at epoch 9 : 0.616905152797699
Loss of batch at epoch 9 : 0.6080234050750732
Loss of batch at epoch 9 : 0.60259610414505
Loss of batch at epoch 9 : 0.6458148956298828
Loss of batch at epoch 9 : 0.5927846431732178
Loss of batch at epoch 9 : 0.6448212265968323
Loss of batch at epoch 9 : 0.705197811126709
Loss of batch at epoch 9 : 0.6604202389717102
Loss of batch at epoch 9 : 0.5935294032096863
Loss of batch at epoch 9 : 0.6405104398727417
Loss of batch at epoch 9 : 0.6307656764984131
Loss of batch at epoch 9 : 0.6840977668762207
Loss of batch at epoch 9 : 0.6866976618766785
Average train loss of epoch 9: 0.013016749888413694
Average validation loss of epoch 9: 0.012952131855768788
Loss of batch at epoch 10 : 0.5929524898529053
Loss of batch at epoch 10 : 0.6504835486412048
Loss of batch at epoch 10 : 0.6092047691345215
Loss of batch at epoch 10 : 0.644945502281189
Loss of batch at epoch 10 : 0.5900499820709229
Loss of batch at epoch 10 : 0.6968547701835632
Loss of batch at epoch 10 : 0.5692254900932312
Loss of batch at epoch 10 : 0.6356576681137085
Loss of batch at epoch 10 : 0.6599385142326355
Loss of batch at epoch 10 : 0.6695252060890198
Loss of batch at epoch 10 : 0.6240217089653015
Loss of batch at epoch 10 : 0.628974437713623
Loss of batch at epoch 10 : 0.6777448654174805
Loss of batch at epoch 10 : 0.7073372006416321
Loss of batch at epoch 10 : 0.5634828805923462
Loss of batch at epoch 10 : 0.6043428182601929
Loss of batch at epoch 10 : 0.6283607482910156
Loss of batch at epoch 10 : 0.6912989020347595
Loss of batch at epoch 10 : 0.6014395952224731
Loss of batch at epoch 10 : 0.6169891357421875
Loss of batch at epoch 10 : 0.6529358625411987
Loss of batch at epoch 10 : 0.681058406829834
Loss of batch at epoch 10 : 0.5914810299873352
Loss of batch at epoch 10 : 0.647389829158783
Loss of batch at epoch 10 : 0.6321994066238403
Loss of batch at epoch 10 : 0.6294600963592529
Loss of batch at epoch 10 : 0.6557769179344177
Loss of batch at epoch 10 : 0.6274770498275757
Loss of batch at epoch 10 : 0.576103150844574
Loss of batch at epoch 10 : 0.5918210744857788
Loss of batch at epoch 10 : 0.5602869987487793
Loss of batch at epoch 10 : 0.5382714867591858
Loss of batch at epoch 10 : 0.6521018147468567
Loss of batch at epoch 10 : 0.5708799362182617
Loss of batch at epoch 10 : 0.6052033305168152
Loss of batch at epoch 10 : 0.5580855011940002
Loss of batch at epoch 10 : 0.6959413886070251
Loss of batch at epoch 10 : 0.652865469455719
Loss of batch at epoch 10 : 0.5845223069190979
Loss of batch at epoch 10 : 0.6304600834846497
Loss of batch at epoch 10 : 0.6072666645050049
Loss of batch at epoch 10 : 0.6120615601539612
Loss of batch at epoch 10 : 0.6563931703567505
Loss of batch at epoch 10 : 0.6249616146087646
Loss of batch at epoch 10 : 0.6050328612327576
Loss of batch at epoch 10 : 0.6430695652961731
Loss of batch at epoch 10 : 0.5979440808296204
Loss of batch at epoch 10 : 0.6043251752853394
Loss of batch at epoch 10 : 0.6013174653053284
Loss of batch at epoch 10 : 0.6062856316566467
Loss of batch at epoch 10 : 0.6122111082077026
Loss of batch at epoch 10 : 0.6911269426345825
Loss of batch at epoch 10 : 0.6072039008140564
Loss of batch at epoch 10 : 0.6278294920921326
Average train loss of epoch 10: 0.012581847335439373
Average validation loss of epoch 10: 0.012721798636696556
Loss of batch at epoch 11 : 0.6058549284934998
Loss of batch at epoch 11 : 0.5663642287254333
Loss of batch at epoch 11 : 0.6322706341743469
Loss of batch at epoch 11 : 0.6199433207511902
Loss of batch at epoch 11 : 0.5596178770065308
Loss of batch at epoch 11 : 0.5440952777862549
Loss of batch at epoch 11 : 0.5855578780174255
Loss of batch at epoch 11 : 0.6407293677330017
Loss of batch at epoch 11 : 0.5659388303756714
Loss of batch at epoch 11 : 0.6076147556304932
Loss of batch at epoch 11 : 0.6036356687545776
Loss of batch at epoch 11 : 0.6244017481803894
Loss of batch at epoch 11 : 0.5938084721565247
Loss of batch at epoch 11 : 0.5711506605148315
Loss of batch at epoch 11 : 0.5775548219680786
Loss of batch at epoch 11 : 0.6205559968948364
Loss of batch at epoch 11 : 0.5897617936134338
Loss of batch at epoch 11 : 0.5731105804443359
Loss of batch at epoch 11 : 0.5747237205505371
Loss of batch at epoch 11 : 0.5967538952827454
Loss of batch at epoch 11 : 0.6626100540161133
Loss of batch at epoch 11 : 0.5487789511680603
Loss of batch at epoch 11 : 0.6073323488235474
Loss of batch at epoch 11 : 0.6564455628395081
Loss of batch at epoch 11 : 0.5466331839561462
Loss of batch at epoch 11 : 0.5899487137794495
Loss of batch at epoch 11 : 0.5553257465362549
Loss of batch at epoch 11 : 0.6237174868583679
Loss of batch at epoch 11 : 0.61783766746521
Loss of batch at epoch 11 : 0.6445654630661011
Loss of batch at epoch 11 : 0.6050474047660828
Loss of batch at epoch 11 : 0.5795301795005798
Loss of batch at epoch 11 : 0.6530033349990845
Loss of batch at epoch 11 : 0.588750422000885
Loss of batch at epoch 11 : 0.7168408632278442
Loss of batch at epoch 11 : 0.6504713892936707
Loss of batch at epoch 11 : 0.5718059539794922
Loss of batch at epoch 11 : 0.6318026185035706
Loss of batch at epoch 11 : 0.6087412238121033
Loss of batch at epoch 11 : 0.5857378840446472
Loss of batch at epoch 11 : 0.6115560531616211
Loss of batch at epoch 11 : 0.6226828098297119
Loss of batch at epoch 11 : 0.6209256052970886
Loss of batch at epoch 11 : 0.5797275900840759
Loss of batch at epoch 11 : 0.5875940918922424
Loss of batch at epoch 11 : 0.6299142837524414
Loss of batch at epoch 11 : 0.5997761487960815
Loss of batch at epoch 11 : 0.6388060450553894
Loss of batch at epoch 11 : 0.5489075779914856
Loss of batch at epoch 11 : 0.6502220630645752
Loss of batch at epoch 11 : 0.5823790431022644
Loss of batch at epoch 11 : 0.6339894533157349
Loss of batch at epoch 11 : 0.5608665347099304
Loss of batch at epoch 11 : 0.5950784087181091
Average train loss of epoch 11: 0.012158625334211923
Average validation loss of epoch 11: 0.012601120303375552
Loss of batch at epoch 12 : 0.6298174262046814
Loss of batch at epoch 12 : 0.6126229166984558
Loss of batch at epoch 12 : 0.5857738852500916
Loss of batch at epoch 12 : 0.5921134948730469
Loss of batch at epoch 12 : 0.6265504956245422
Loss of batch at epoch 12 : 0.5862709879875183
Loss of batch at epoch 12 : 0.5324435830116272
Loss of batch at epoch 12 : 0.6198778748512268
Loss of batch at epoch 12 : 0.6183463931083679
Loss of batch at epoch 12 : 0.5579951405525208
Loss of batch at epoch 12 : 0.5410854816436768
Loss of batch at epoch 12 : 0.6471048593521118
Loss of batch at epoch 12 : 0.5899412631988525
Loss of batch at epoch 12 : 0.6355643272399902
Loss of batch at epoch 12 : 0.580636739730835
Loss of batch at epoch 12 : 0.6019636988639832
Loss of batch at epoch 12 : 0.6136387586593628
Loss of batch at epoch 12 : 0.562939465045929
Loss of batch at epoch 12 : 0.5325540900230408
Loss of batch at epoch 12 : 0.5906189680099487
Loss of batch at epoch 12 : 0.6220604181289673
Loss of batch at epoch 12 : 0.5765120983123779
Loss of batch at epoch 12 : 0.6764937043190002
Loss of batch at epoch 12 : 0.5938133001327515
Loss of batch at epoch 12 : 0.5728138089179993
Loss of batch at epoch 12 : 0.5974764823913574
Loss of batch at epoch 12 : 0.6336321830749512
Loss of batch at epoch 12 : 0.5680358409881592
Loss of batch at epoch 12 : 0.5450174808502197
Loss of batch at epoch 12 : 0.5485878586769104
Loss of batch at epoch 12 : 0.5932741761207581
Loss of batch at epoch 12 : 0.573999285697937
Loss of batch at epoch 12 : 0.5744945406913757
Loss of batch at epoch 12 : 0.6183679699897766
Loss of batch at epoch 12 : 0.5461671352386475
Loss of batch at epoch 12 : 0.5491448640823364
Loss of batch at epoch 12 : 0.5503574013710022
Loss of batch at epoch 12 : 0.5754910111427307
Loss of batch at epoch 12 : 0.5463991165161133
Loss of batch at epoch 12 : 0.5935384035110474
Loss of batch at epoch 12 : 0.5743513703346252
Loss of batch at epoch 12 : 0.5571843385696411
Loss of batch at epoch 12 : 0.5459940433502197
Loss of batch at epoch 12 : 0.5119571089744568
Loss of batch at epoch 12 : 0.635446310043335
Loss of batch at epoch 12 : 0.6110852956771851
Loss of batch at epoch 12 : 0.579054594039917
Loss of batch at epoch 12 : 0.5911329388618469
Loss of batch at epoch 12 : 0.5884645581245422
Loss of batch at epoch 12 : 0.5843994617462158
Loss of batch at epoch 12 : 0.5486775636672974
Loss of batch at epoch 12 : 0.630410373210907
Loss of batch at epoch 12 : 0.58402419090271
Loss of batch at epoch 12 : 0.5701636672019958
Average train loss of epoch 12: 0.01180951785827591
Average validation loss of epoch 12: 0.012119643214575771
Loss of batch at epoch 13 : 0.5826534628868103
Loss of batch at epoch 13 : 0.5715844035148621
Loss of batch at epoch 13 : 0.6202943921089172
Loss of batch at epoch 13 : 0.5763142108917236
Loss of batch at epoch 13 : 0.5430113673210144
Loss of batch at epoch 13 : 0.6113125085830688
Loss of batch at epoch 13 : 0.5789661407470703
Loss of batch at epoch 13 : 0.5445032715797424
Loss of batch at epoch 13 : 0.593889057636261
Loss of batch at epoch 13 : 0.5861110091209412
Loss of batch at epoch 13 : 0.535946249961853
Loss of batch at epoch 13 : 0.6327770948410034
Loss of batch at epoch 13 : 0.5391257405281067
Loss of batch at epoch 13 : 0.5762861371040344
Loss of batch at epoch 13 : 0.5805187821388245
Loss of batch at epoch 13 : 0.5502382516860962
Loss of batch at epoch 13 : 0.5182495713233948
Loss of batch at epoch 13 : 0.5328402519226074
Loss of batch at epoch 13 : 0.5826724171638489
Loss of batch at epoch 13 : 0.5579965710639954
Loss of batch at epoch 13 : 0.5892941355705261
Loss of batch at epoch 13 : 0.5286563038825989
Loss of batch at epoch 13 : 0.5465071797370911
Loss of batch at epoch 13 : 0.5533161759376526
Loss of batch at epoch 13 : 0.5768176317214966
Loss of batch at epoch 13 : 0.5904940366744995
Loss of batch at epoch 13 : 0.6578683853149414
Loss of batch at epoch 13 : 0.5732921361923218
Loss of batch at epoch 13 : 0.5463517308235168
Loss of batch at epoch 13 : 0.5699397921562195
Loss of batch at epoch 13 : 0.5680071711540222
Loss of batch at epoch 13 : 0.5925827026367188
Loss of batch at epoch 13 : 0.5313700437545776
Loss of batch at epoch 13 : 0.5458051562309265
Loss of batch at epoch 13 : 0.5214847922325134
Loss of batch at epoch 13 : 0.598934531211853
Loss of batch at epoch 13 : 0.6377504467964172
Loss of batch at epoch 13 : 0.542080283164978
Loss of batch at epoch 13 : 0.5382837653160095
Loss of batch at epoch 13 : 0.6061263680458069
Loss of batch at epoch 13 : 0.6332162618637085
Loss of batch at epoch 13 : 0.5267021059989929
Loss of batch at epoch 13 : 0.5834163427352905
Loss of batch at epoch 13 : 0.5522034764289856
Loss of batch at epoch 13 : 0.5675095915794373
Loss of batch at epoch 13 : 0.5631476640701294
Loss of batch at epoch 13 : 0.5932988524436951
Loss of batch at epoch 13 : 0.6099087595939636
Loss of batch at epoch 13 : 0.5696554780006409
Loss of batch at epoch 13 : 0.5267559289932251
Loss of batch at epoch 13 : 0.5041048526763916
Loss of batch at epoch 13 : 0.6386419534683228
Loss of batch at epoch 13 : 0.5606196522712708
Loss of batch at epoch 13 : 0.565149188041687
Average train loss of epoch 13: 0.011510300582874347
Average validation loss of epoch 13: 0.01165800544147941
Loss of batch at epoch 14 : 0.5384990572929382
Loss of batch at epoch 14 : 0.49864962697029114
Loss of batch at epoch 14 : 0.5092868804931641
Loss of batch at epoch 14 : 0.5519489049911499
Loss of batch at epoch 14 : 0.5551897883415222
Loss of batch at epoch 14 : 0.5667983293533325
Loss of batch at epoch 14 : 0.5717886090278625
Loss of batch at epoch 14 : 0.5882012248039246
Loss of batch at epoch 14 : 0.5399965643882751
Loss of batch at epoch 14 : 0.5834710597991943
Loss of batch at epoch 14 : 0.49571460485458374
Loss of batch at epoch 14 : 0.6076341867446899
Loss of batch at epoch 14 : 0.6185498833656311
Loss of batch at epoch 14 : 0.5431438088417053
Loss of batch at epoch 14 : 0.5661007165908813
Loss of batch at epoch 14 : 0.5355395078659058
Loss of batch at epoch 14 : 0.5892099142074585
Loss of batch at epoch 14 : 0.5989554524421692
Loss of batch at epoch 14 : 0.5607463717460632
Loss of batch at epoch 14 : 0.5863325595855713
Loss of batch at epoch 14 : 0.5583226084709167
Loss of batch at epoch 14 : 0.5520311594009399
Loss of batch at epoch 14 : 0.5468789339065552
Loss of batch at epoch 14 : 0.6297937631607056
Loss of batch at epoch 14 : 0.5219486355781555
Loss of batch at epoch 14 : 0.5192611217498779
Loss of batch at epoch 14 : 0.555911123752594
Loss of batch at epoch 14 : 0.548928439617157
Loss of batch at epoch 14 : 0.5556660294532776
Loss of batch at epoch 14 : 0.5466619729995728
Loss of batch at epoch 14 : 0.5738167762756348
Loss of batch at epoch 14 : 0.5526836514472961
Loss of batch at epoch 14 : 0.5543252825737
Loss of batch at epoch 14 : 0.5806994438171387
Loss of batch at epoch 14 : 0.6118840575218201
Loss of batch at epoch 14 : 0.6032941937446594
Loss of batch at epoch 14 : 0.529473066329956
Loss of batch at epoch 14 : 0.5672879815101624
Loss of batch at epoch 14 : 0.513401448726654
Loss of batch at epoch 14 : 0.5822380185127258
Loss of batch at epoch 14 : 0.5314140319824219
Loss of batch at epoch 14 : 0.5631901025772095
Loss of batch at epoch 14 : 0.5417399406433105
Loss of batch at epoch 14 : 0.5584191679954529
Loss of batch at epoch 14 : 0.5357292294502258
Loss of batch at epoch 14 : 0.5108872652053833
Loss of batch at epoch 14 : 0.5544067621231079
Loss of batch at epoch 14 : 0.5772566795349121
Loss of batch at epoch 14 : 0.5685439705848694
Loss of batch at epoch 14 : 0.5329092741012573
Loss of batch at epoch 14 : 0.5623927712440491
Loss of batch at epoch 14 : 0.5367565751075745
Loss of batch at epoch 14 : 0.5820884108543396
Loss of batch at epoch 14 : 0.5374409556388855
Average train loss of epoch 14: 0.011241014721324143
Average validation loss of epoch 14: 0.011319919868751808
Loss of batch at epoch 15 : 0.5437846779823303
Loss of batch at epoch 15 : 0.5696115493774414
Loss of batch at epoch 15 : 0.5772212147712708
Loss of batch at epoch 15 : 0.5148818492889404
Loss of batch at epoch 15 : 0.5473462343215942
Loss of batch at epoch 15 : 0.5195268392562866
Loss of batch at epoch 15 : 0.5433498024940491
Loss of batch at epoch 15 : 0.535322904586792
Loss of batch at epoch 15 : 0.5142759680747986
Loss of batch at epoch 15 : 0.5371946692466736
Loss of batch at epoch 15 : 0.551658570766449
Loss of batch at epoch 15 : 0.6048924922943115
Loss of batch at epoch 15 : 0.5403537750244141
Loss of batch at epoch 15 : 0.5669417381286621
Loss of batch at epoch 15 : 0.5234284996986389
Loss of batch at epoch 15 : 0.5429386496543884
Loss of batch at epoch 15 : 0.5172121524810791
Loss of batch at epoch 15 : 0.5292925834655762
Loss of batch at epoch 15 : 0.5038242340087891
Loss of batch at epoch 15 : 0.5704345107078552
Loss of batch at epoch 15 : 0.5311926007270813
Loss of batch at epoch 15 : 0.5678076148033142
Loss of batch at epoch 15 : 0.5287461280822754
Loss of batch at epoch 15 : 0.4961206316947937
Loss of batch at epoch 15 : 0.5409858226776123
Loss of batch at epoch 15 : 0.5400323867797852
Loss of batch at epoch 15 : 0.5280030965805054
Loss of batch at epoch 15 : 0.5578870177268982
Loss of batch at epoch 15 : 0.5562145113945007
Loss of batch at epoch 15 : 0.6433233618736267
Loss of batch at epoch 15 : 0.5507379770278931
Loss of batch at epoch 15 : 0.5349146127700806
Loss of batch at epoch 15 : 0.5225409269332886
Loss of batch at epoch 15 : 0.4904809296131134
Loss of batch at epoch 15 : 0.5143182873725891
Loss of batch at epoch 15 : 0.5403087735176086
Loss of batch at epoch 15 : 0.5899350047111511
Loss of batch at epoch 15 : 0.5214341878890991
Loss of batch at epoch 15 : 0.5366537570953369
Loss of batch at epoch 15 : 0.5392321944236755
Loss of batch at epoch 15 : 0.5146969556808472
Loss of batch at epoch 15 : 0.507271409034729
Loss of batch at epoch 15 : 0.4977608621120453
Loss of batch at epoch 15 : 0.536612868309021
Loss of batch at epoch 15 : 0.5150284767150879
Loss of batch at epoch 15 : 0.5111450552940369
Loss of batch at epoch 15 : 0.5363884568214417
Loss of batch at epoch 15 : 0.5158349275588989
Loss of batch at epoch 15 : 0.5270715355873108
Loss of batch at epoch 15 : 0.5560049414634705
Loss of batch at epoch 15 : 0.5136748552322388
Loss of batch at epoch 15 : 0.5515667796134949
Loss of batch at epoch 15 : 0.5456452369689941
Loss of batch at epoch 15 : 0.5816710591316223
Average train loss of epoch 15: 0.010864351114468223
Average validation loss of epoch 15: 0.011454697811242306
Loss of batch at epoch 16 : 0.5152292251586914
Loss of batch at epoch 16 : 0.49984410405158997
Loss of batch at epoch 16 : 0.5516676306724548
Loss of batch at epoch 16 : 0.4879453182220459
Loss of batch at epoch 16 : 0.6191359758377075
Loss of batch at epoch 16 : 0.567638099193573
Loss of batch at epoch 16 : 0.509110152721405
Loss of batch at epoch 16 : 0.5172128081321716
Loss of batch at epoch 16 : 0.4962626099586487
Loss of batch at epoch 16 : 0.4950529932975769
Loss of batch at epoch 16 : 0.5799542665481567
Loss of batch at epoch 16 : 0.4882325530052185
Loss of batch at epoch 16 : 0.49760937690734863
Loss of batch at epoch 16 : 0.5203895568847656
Loss of batch at epoch 16 : 0.60319584608078
Loss of batch at epoch 16 : 0.5598281025886536
Loss of batch at epoch 16 : 0.5390187501907349
Loss of batch at epoch 16 : 0.4846865236759186
Loss of batch at epoch 16 : 0.5731949210166931
Loss of batch at epoch 16 : 0.5320201516151428
Loss of batch at epoch 16 : 0.5197831988334656
Loss of batch at epoch 16 : 0.4884522557258606
Loss of batch at epoch 16 : 0.5359644293785095
Loss of batch at epoch 16 : 0.5800114274024963
Loss of batch at epoch 16 : 0.5715150237083435
Loss of batch at epoch 16 : 0.5948655605316162
Loss of batch at epoch 16 : 0.5601412653923035
Loss of batch at epoch 16 : 0.5504526495933533
Loss of batch at epoch 16 : 0.5349575281143188
Loss of batch at epoch 16 : 0.5153330564498901
Loss of batch at epoch 16 : 0.5363872051239014
Loss of batch at epoch 16 : 0.5047409534454346
Loss of batch at epoch 16 : 0.555819571018219
Loss of batch at epoch 16 : 0.5179776549339294
Loss of batch at epoch 16 : 0.5284737348556519
Loss of batch at epoch 16 : 0.5595207214355469
Loss of batch at epoch 16 : 0.5543655157089233
Loss of batch at epoch 16 : 0.5594505667686462
Loss of batch at epoch 16 : 0.5188062191009521
Loss of batch at epoch 16 : 0.4880776107311249
Loss of batch at epoch 16 : 0.5262681841850281
Loss of batch at epoch 16 : 0.5900465846061707
Loss of batch at epoch 16 : 0.5419183373451233
Loss of batch at epoch 16 : 0.506180465221405
Loss of batch at epoch 16 : 0.5544933676719666
Loss of batch at epoch 16 : 0.5088037848472595
Loss of batch at epoch 16 : 0.49044111371040344
Loss of batch at epoch 16 : 0.5068604350090027
Loss of batch at epoch 16 : 0.5193239450454712
Loss of batch at epoch 16 : 0.5261540412902832
Loss of batch at epoch 16 : 0.4867004454135895
Loss of batch at epoch 16 : 0.5263221263885498
Loss of batch at epoch 16 : 0.5471892356872559
Loss of batch at epoch 16 : 0.5186108946800232
Average train loss of epoch 16: 0.010739966770710565
Average validation loss of epoch 16: 0.011361497821229877
Loss of batch at epoch 17 : 0.5049338936805725
Loss of batch at epoch 17 : 0.5556142926216125
Loss of batch at epoch 17 : 0.5055087804794312
Loss of batch at epoch 17 : 0.6112905740737915
Loss of batch at epoch 17 : 0.5585225820541382
Loss of batch at epoch 17 : 0.5033890604972839
Loss of batch at epoch 17 : 0.5309051871299744
Loss of batch at epoch 17 : 0.5454835891723633
Loss of batch at epoch 17 : 0.509040892124176
Loss of batch at epoch 17 : 0.5037663578987122
Loss of batch at epoch 17 : 0.5184686779975891
Loss of batch at epoch 17 : 0.5673606991767883
Loss of batch at epoch 17 : 0.4904893636703491
Loss of batch at epoch 17 : 0.5206414461135864
Loss of batch at epoch 17 : 0.5305928587913513
Loss of batch at epoch 17 : 0.48979249596595764
Loss of batch at epoch 17 : 0.4882241487503052
Loss of batch at epoch 17 : 0.4925519526004791
Loss of batch at epoch 17 : 0.508605420589447
Loss of batch at epoch 17 : 0.5408529043197632
Loss of batch at epoch 17 : 0.5233727097511292
Loss of batch at epoch 17 : 0.5325722098350525
Loss of batch at epoch 17 : 0.4695548117160797
Loss of batch at epoch 17 : 0.5508382320404053
Loss of batch at epoch 17 : 0.533545732498169
Loss of batch at epoch 17 : 0.4833797216415405
Loss of batch at epoch 17 : 0.5372560620307922
Loss of batch at epoch 17 : 0.4778272807598114
Loss of batch at epoch 17 : 0.5168261528015137
Loss of batch at epoch 17 : 0.5853988528251648
Loss of batch at epoch 17 : 0.49423956871032715
Loss of batch at epoch 17 : 0.5322225093841553
Loss of batch at epoch 17 : 0.5592902898788452
Loss of batch at epoch 17 : 0.5397129058837891
Loss of batch at epoch 17 : 0.555216372013092
Loss of batch at epoch 17 : 0.44208478927612305
Loss of batch at epoch 17 : 0.52013099193573
Loss of batch at epoch 17 : 0.538934051990509
Loss of batch at epoch 17 : 0.5546088814735413
Loss of batch at epoch 17 : 0.5520099401473999
Loss of batch at epoch 17 : 0.5276581048965454
Loss of batch at epoch 17 : 0.6197635531425476
Loss of batch at epoch 17 : 0.5050148367881775
Loss of batch at epoch 17 : 0.45677611231803894
Loss of batch at epoch 17 : 0.5232828855514526
Loss of batch at epoch 17 : 0.5762286186218262
Loss of batch at epoch 17 : 0.47429484128952026
Loss of batch at epoch 17 : 0.5051246881484985
Loss of batch at epoch 17 : 0.49003520607948303
Loss of batch at epoch 17 : 0.4958076477050781
Loss of batch at epoch 17 : 0.5280308723449707
Loss of batch at epoch 17 : 0.4994598627090454
Loss of batch at epoch 17 : 0.5017971396446228
Loss of batch at epoch 17 : 0.49638405442237854
Average train loss of epoch 17: 0.010520804720729745
Average validation loss of epoch 17: 0.011042851791638717
Loss of batch at epoch 18 : 0.5364252924919128
Loss of batch at epoch 18 : 0.4859960079193115
Loss of batch at epoch 18 : 0.46926090121269226
Loss of batch at epoch 18 : 0.4706012010574341
Loss of batch at epoch 18 : 0.5500422120094299
Loss of batch at epoch 18 : 0.5591793060302734
Loss of batch at epoch 18 : 0.5341579914093018
Loss of batch at epoch 18 : 0.581859827041626
Loss of batch at epoch 18 : 0.4877547025680542
Loss of batch at epoch 18 : 0.5359975695610046
Loss of batch at epoch 18 : 0.5473507642745972
Loss of batch at epoch 18 : 0.5047734379768372
Loss of batch at epoch 18 : 0.47433289885520935
Loss of batch at epoch 18 : 0.4903786778450012
Loss of batch at epoch 18 : 0.5416035056114197
Loss of batch at epoch 18 : 0.5456780195236206
Loss of batch at epoch 18 : 0.5033292174339294
Loss of batch at epoch 18 : 0.5285371541976929
Loss of batch at epoch 18 : 0.49011164903640747
Loss of batch at epoch 18 : 0.5329710841178894
Loss of batch at epoch 18 : 0.5227237343788147
Loss of batch at epoch 18 : 0.5300209522247314
Loss of batch at epoch 18 : 0.5969617962837219
Loss of batch at epoch 18 : 0.4697989523410797
Loss of batch at epoch 18 : 0.49732470512390137
Loss of batch at epoch 18 : 0.5227774977684021
Loss of batch at epoch 18 : 0.4833420515060425
Loss of batch at epoch 18 : 0.46994057297706604
Loss of batch at epoch 18 : 0.5186582207679749
Loss of batch at epoch 18 : 0.4869895577430725
Loss of batch at epoch 18 : 0.5013321042060852
Loss of batch at epoch 18 : 0.5395805835723877
Loss of batch at epoch 18 : 0.5332304239273071
Loss of batch at epoch 18 : 0.5099824666976929
Loss of batch at epoch 18 : 0.5350048542022705
Loss of batch at epoch 18 : 0.5298056602478027
Loss of batch at epoch 18 : 0.48140475153923035
Loss of batch at epoch 18 : 0.4790564179420471
Loss of batch at epoch 18 : 0.5355693101882935
Loss of batch at epoch 18 : 0.510989785194397
Loss of batch at epoch 18 : 0.5531871914863586
Loss of batch at epoch 18 : 0.507746160030365
Loss of batch at epoch 18 : 0.4891316294670105
Loss of batch at epoch 18 : 0.4597164988517761
Loss of batch at epoch 18 : 0.5601802468299866
Loss of batch at epoch 18 : 0.5052098035812378
Loss of batch at epoch 18 : 0.4847767949104309
Loss of batch at epoch 18 : 0.46726498007774353
Loss of batch at epoch 18 : 0.5310476422309875
Loss of batch at epoch 18 : 0.5508269667625427
Loss of batch at epoch 18 : 0.4635159373283386
Loss of batch at epoch 18 : 0.5088620781898499
Loss of batch at epoch 18 : 0.45108452439308167
Loss of batch at epoch 18 : 0.5126761794090271
Average train loss of epoch 18: 0.010332362521843202
Average validation loss of epoch 18: 0.010985795897666854
Loss of batch at epoch 19 : 0.511803925037384
Loss of batch at epoch 19 : 0.48191672563552856
Loss of batch at epoch 19 : 0.5533974766731262
Loss of batch at epoch 19 : 0.503304123878479
Loss of batch at epoch 19 : 0.4926696717739105
Loss of batch at epoch 19 : 0.5066638588905334
Loss of batch at epoch 19 : 0.46306318044662476
Loss of batch at epoch 19 : 0.5164532661437988
Loss of batch at epoch 19 : 0.5372985601425171
Loss of batch at epoch 19 : 0.4569980800151825
Loss of batch at epoch 19 : 0.47722169756889343
Loss of batch at epoch 19 : 0.461069792509079
Loss of batch at epoch 19 : 0.5159701704978943
Loss of batch at epoch 19 : 0.5006170868873596
Loss of batch at epoch 19 : 0.47634267807006836
Loss of batch at epoch 19 : 0.5031783580780029
Loss of batch at epoch 19 : 0.5265818238258362
Loss of batch at epoch 19 : 0.503919780254364
Loss of batch at epoch 19 : 0.5518444180488586
Loss of batch at epoch 19 : 0.5536327958106995
Loss of batch at epoch 19 : 0.5229665040969849
Loss of batch at epoch 19 : 0.5180379152297974
Loss of batch at epoch 19 : 0.46021798253059387
Loss of batch at epoch 19 : 0.5330591797828674
Loss of batch at epoch 19 : 0.48774847388267517
Loss of batch at epoch 19 : 0.486715167760849
Loss of batch at epoch 19 : 0.5059773325920105
Loss of batch at epoch 19 : 0.4916505813598633
Loss of batch at epoch 19 : 0.49731042981147766
Loss of batch at epoch 19 : 0.5224378705024719
Loss of batch at epoch 19 : 0.5020295977592468
Loss of batch at epoch 19 : 0.4760235846042633
Loss of batch at epoch 19 : 0.5027338266372681
Loss of batch at epoch 19 : 0.5161285400390625
Loss of batch at epoch 19 : 0.4803467094898224
Loss of batch at epoch 19 : 0.4954919219017029
Loss of batch at epoch 19 : 0.47423526644706726
Loss of batch at epoch 19 : 0.45615097880363464
Loss of batch at epoch 19 : 0.5299995541572571
Loss of batch at epoch 19 : 0.5265288352966309
Loss of batch at epoch 19 : 0.5020192861557007
Loss of batch at epoch 19 : 0.4990588128566742
Loss of batch at epoch 19 : 0.5209545493125916
Loss of batch at epoch 19 : 0.4746870994567871
Loss of batch at epoch 19 : 0.5197343230247498
Loss of batch at epoch 19 : 0.549103319644928
Loss of batch at epoch 19 : 0.5259202122688293
Loss of batch at epoch 19 : 0.5030430555343628
Loss of batch at epoch 19 : 0.5287669897079468
Loss of batch at epoch 19 : 0.46328118443489075
Loss of batch at epoch 19 : 0.5595721006393433
Loss of batch at epoch 19 : 0.44986972212791443
Loss of batch at epoch 19 : 0.5161198377609253
Loss of batch at epoch 19 : 0.5625569224357605
Average train loss of epoch 19: 0.010177155053820336
Average validation loss of epoch 19: 0.010682453611483076
Loss of batch at epoch 20 : 0.4706508219242096
Loss of batch at epoch 20 : 0.44082435965538025
Loss of batch at epoch 20 : 0.5099912881851196
Loss of batch at epoch 20 : 0.4827944338321686
Loss of batch at epoch 20 : 0.5029585957527161
Loss of batch at epoch 20 : 0.4564720690250397
Loss of batch at epoch 20 : 0.5264224410057068
Loss of batch at epoch 20 : 0.47262731194496155
Loss of batch at epoch 20 : 0.4576174318790436
Loss of batch at epoch 20 : 0.5241393446922302
Loss of batch at epoch 20 : 0.4888668954372406
Loss of batch at epoch 20 : 0.4967527687549591
Loss of batch at epoch 20 : 0.5223119854927063
Loss of batch at epoch 20 : 0.5156450271606445
Loss of batch at epoch 20 : 0.5183758735656738
Loss of batch at epoch 20 : 0.461546391248703
Loss of batch at epoch 20 : 0.4956530034542084
Loss of batch at epoch 20 : 0.5081517696380615
Loss of batch at epoch 20 : 0.4863109886646271
Loss of batch at epoch 20 : 0.5216509103775024
Loss of batch at epoch 20 : 0.4835481643676758
Loss of batch at epoch 20 : 0.507150411605835
Loss of batch at epoch 20 : 0.5010583400726318
Loss of batch at epoch 20 : 0.5259886384010315
Loss of batch at epoch 20 : 0.5192691683769226
Loss of batch at epoch 20 : 0.5195307731628418
Loss of batch at epoch 20 : 0.4816880524158478
Loss of batch at epoch 20 : 0.49907058477401733
Loss of batch at epoch 20 : 0.4873286783695221
Loss of batch at epoch 20 : 0.47577083110809326
Loss of batch at epoch 20 : 0.4871087372303009
Loss of batch at epoch 20 : 0.5044364929199219
Loss of batch at epoch 20 : 0.5096324682235718
Loss of batch at epoch 20 : 0.5261009335517883
Loss of batch at epoch 20 : 0.5643733739852905
Loss of batch at epoch 20 : 0.49817323684692383
Loss of batch at epoch 20 : 0.5007330179214478
Loss of batch at epoch 20 : 0.4900129437446594
Loss of batch at epoch 20 : 0.4825395345687866
Loss of batch at epoch 20 : 0.5248137712478638
Loss of batch at epoch 20 : 0.43604445457458496
Loss of batch at epoch 20 : 0.5210676193237305
Loss of batch at epoch 20 : 0.5079466700553894
Loss of batch at epoch 20 : 0.4565456211566925
Loss of batch at epoch 20 : 0.4915491044521332
Loss of batch at epoch 20 : 0.5476961731910706
Loss of batch at epoch 20 : 0.4997301697731018
Loss of batch at epoch 20 : 0.46627306938171387
Loss of batch at epoch 20 : 0.4910286068916321
Loss of batch at epoch 20 : 0.49813348054885864
Loss of batch at epoch 20 : 0.5319125652313232
Loss of batch at epoch 20 : 0.44879573583602905
Loss of batch at epoch 20 : 0.4909078776836395
Loss of batch at epoch 20 : 0.4891386330127716
Average train loss of epoch 20: 0.010016751164727642
Average validation loss of epoch 20: 0.010508239469945632
Loss of batch at epoch 21 : 0.5572081208229065
Loss of batch at epoch 21 : 0.45625779032707214
Loss of batch at epoch 21 : 0.4836222231388092
Loss of batch at epoch 21 : 0.4411804974079132
Loss of batch at epoch 21 : 0.4620659351348877
Loss of batch at epoch 21 : 0.4483795464038849
Loss of batch at epoch 21 : 0.48747342824935913
Loss of batch at epoch 21 : 0.4736989140510559
Loss of batch at epoch 21 : 0.5036808252334595
Loss of batch at epoch 21 : 0.4954630732536316
Loss of batch at epoch 21 : 0.47368285059928894
Loss of batch at epoch 21 : 0.4908856749534607
Loss of batch at epoch 21 : 0.5194207429885864
Loss of batch at epoch 21 : 0.5129861235618591
Loss of batch at epoch 21 : 0.5041654706001282
Loss of batch at epoch 21 : 0.4872705042362213
Loss of batch at epoch 21 : 0.5140054821968079
Loss of batch at epoch 21 : 0.4755556881427765
Loss of batch at epoch 21 : 0.4941669702529907
Loss of batch at epoch 21 : 0.4563911557197571
Loss of batch at epoch 21 : 0.47576576471328735
Loss of batch at epoch 21 : 0.4298960864543915
Loss of batch at epoch 21 : 0.5086272954940796
Loss of batch at epoch 21 : 0.5327208638191223
Loss of batch at epoch 21 : 0.44285938143730164
Loss of batch at epoch 21 : 0.4888566732406616
Loss of batch at epoch 21 : 0.46287238597869873
Loss of batch at epoch 21 : 0.5192089080810547
Loss of batch at epoch 21 : 0.5132157802581787
Loss of batch at epoch 21 : 0.4581856429576874
Loss of batch at epoch 21 : 0.46569326519966125
Loss of batch at epoch 21 : 0.4861278831958771
Loss of batch at epoch 21 : 0.4529147446155548
Loss of batch at epoch 21 : 0.4588421881198883
Loss of batch at epoch 21 : 0.463496595621109
Loss of batch at epoch 21 : 0.5219783782958984
Loss of batch at epoch 21 : 0.4798128008842468
Loss of batch at epoch 21 : 0.49204087257385254
Loss of batch at epoch 21 : 0.5124388337135315
Loss of batch at epoch 21 : 0.4947492480278015
Loss of batch at epoch 21 : 0.46074286103248596
Loss of batch at epoch 21 : 0.4705069661140442
Loss of batch at epoch 21 : 0.5023795962333679
Loss of batch at epoch 21 : 0.4082925021648407
Loss of batch at epoch 21 : 0.5122109055519104
Loss of batch at epoch 21 : 0.43804851174354553
Loss of batch at epoch 21 : 0.4491834044456482
Loss of batch at epoch 21 : 0.5150099992752075
Loss of batch at epoch 21 : 0.4786738455295563
Loss of batch at epoch 21 : 0.517409086227417
Loss of batch at epoch 21 : 0.49542179703712463
Loss of batch at epoch 21 : 0.45290493965148926
Loss of batch at epoch 21 : 0.4568137526512146
Loss of batch at epoch 21 : 0.5233117938041687
Average train loss of epoch 21: 0.009738154336531898
Average validation loss of epoch 21: 0.010443027573402482
Loss of batch at epoch 22 : 0.4455527663230896
Loss of batch at epoch 22 : 0.46646225452423096
Loss of batch at epoch 22 : 0.47202423214912415
Loss of batch at epoch 22 : 0.5441526174545288
Loss of batch at epoch 22 : 0.4841037392616272
Loss of batch at epoch 22 : 0.5003988742828369
Loss of batch at epoch 22 : 0.4559282958507538
Loss of batch at epoch 22 : 0.43903374671936035
Loss of batch at epoch 22 : 0.4562760293483734
Loss of batch at epoch 22 : 0.5002813339233398
Loss of batch at epoch 22 : 0.5405187010765076
Loss of batch at epoch 22 : 0.5043439865112305
Loss of batch at epoch 22 : 0.5639704465866089
Loss of batch at epoch 22 : 0.4693107008934021
Loss of batch at epoch 22 : 0.4316250681877136
Loss of batch at epoch 22 : 0.4983864426612854
Loss of batch at epoch 22 : 0.5458086133003235
Loss of batch at epoch 22 : 0.4947996437549591
Loss of batch at epoch 22 : 0.45266321301460266
Loss of batch at epoch 22 : 0.45384976267814636
Loss of batch at epoch 22 : 0.4542556405067444
Loss of batch at epoch 22 : 0.4527166187763214
Loss of batch at epoch 22 : 0.5295810699462891
Loss of batch at epoch 22 : 0.4812292754650116
Loss of batch at epoch 22 : 0.46016669273376465
Loss of batch at epoch 22 : 0.512142539024353
Loss of batch at epoch 22 : 0.45911622047424316
Loss of batch at epoch 22 : 0.5046302676200867
Loss of batch at epoch 22 : 0.4576701521873474
Loss of batch at epoch 22 : 0.45554301142692566
Loss of batch at epoch 22 : 0.46213239431381226
Loss of batch at epoch 22 : 0.4937208294868469
Loss of batch at epoch 22 : 0.47975292801856995
Loss of batch at epoch 22 : 0.48033249378204346
Loss of batch at epoch 22 : 0.47047609090805054
Loss of batch at epoch 22 : 0.499612033367157
Loss of batch at epoch 22 : 0.4362413287162781
Loss of batch at epoch 22 : 0.4754500389099121
Loss of batch at epoch 22 : 0.4564273953437805
Loss of batch at epoch 22 : 0.46126654744148254
Loss of batch at epoch 22 : 0.4877096116542816
Loss of batch at epoch 22 : 0.47588130831718445
Loss of batch at epoch 22 : 0.4925177991390228
Loss of batch at epoch 22 : 0.46643808484077454
Loss of batch at epoch 22 : 0.5241715908050537
Loss of batch at epoch 22 : 0.45440495014190674
Loss of batch at epoch 22 : 0.49548083543777466
Loss of batch at epoch 22 : 0.47669169306755066
Loss of batch at epoch 22 : 0.4687582850456238
Loss of batch at epoch 22 : 0.4580302834510803
Loss of batch at epoch 22 : 0.46768203377723694
Loss of batch at epoch 22 : 0.5127742290496826
Loss of batch at epoch 22 : 0.4155145287513733
Loss of batch at epoch 22 : 0.4779997169971466
Average train loss of epoch 22: 0.009662438720976621
Average validation loss of epoch 22: 0.010250606119432033
Loss of batch at epoch 23 : 0.4600161015987396
Loss of batch at epoch 23 : 0.42521387338638306
Loss of batch at epoch 23 : 0.4881701171398163
Loss of batch at epoch 23 : 0.49352800846099854
Loss of batch at epoch 23 : 0.4671391546726227
Loss of batch at epoch 23 : 0.47135651111602783
Loss of batch at epoch 23 : 0.45931512117385864
Loss of batch at epoch 23 : 0.4519808888435364
Loss of batch at epoch 23 : 0.4437936842441559
Loss of batch at epoch 23 : 0.4438991844654083
Loss of batch at epoch 23 : 0.46863096952438354
Loss of batch at epoch 23 : 0.48005643486976624
Loss of batch at epoch 23 : 0.5004955530166626
Loss of batch at epoch 23 : 0.4467424154281616
Loss of batch at epoch 23 : 0.4336152970790863
Loss of batch at epoch 23 : 0.4435441195964813
Loss of batch at epoch 23 : 0.48757103085517883
Loss of batch at epoch 23 : 0.4309921860694885
Loss of batch at epoch 23 : 0.45543912053108215
Loss of batch at epoch 23 : 0.4843125641345978
Loss of batch at epoch 23 : 0.493535578250885
Loss of batch at epoch 23 : 0.4465700685977936
Loss of batch at epoch 23 : 0.4170583188533783
Loss of batch at epoch 23 : 0.43787387013435364
Loss of batch at epoch 23 : 0.5121062397956848
Loss of batch at epoch 23 : 0.4290965795516968
Loss of batch at epoch 23 : 0.4662763774394989
Loss of batch at epoch 23 : 0.48909568786621094
Loss of batch at epoch 23 : 0.45719295740127563
Loss of batch at epoch 23 : 0.47603708505630493
Loss of batch at epoch 23 : 0.4955773651599884
Loss of batch at epoch 23 : 0.489202618598938
Loss of batch at epoch 23 : 0.5052008032798767
Loss of batch at epoch 23 : 0.46411967277526855
Loss of batch at epoch 23 : 0.48586562275886536
Loss of batch at epoch 23 : 0.4669484496116638
Loss of batch at epoch 23 : 0.4590509533882141
Loss of batch at epoch 23 : 0.4320068359375
Loss of batch at epoch 23 : 0.46874046325683594
Loss of batch at epoch 23 : 0.4823325276374817
Loss of batch at epoch 23 : 0.46526700258255005
Loss of batch at epoch 23 : 0.5385751128196716
Loss of batch at epoch 23 : 0.47174015641212463
Loss of batch at epoch 23 : 0.4359424114227295
Loss of batch at epoch 23 : 0.5209042429924011
Loss of batch at epoch 23 : 0.4755774438381195
Loss of batch at epoch 23 : 0.46857815980911255
Loss of batch at epoch 23 : 0.5095064043998718
Loss of batch at epoch 23 : 0.4722890853881836
Loss of batch at epoch 23 : 0.469266414642334
Loss of batch at epoch 23 : 0.4982844889163971
Loss of batch at epoch 23 : 0.46265795826911926
Loss of batch at epoch 23 : 0.46718236804008484
Loss of batch at epoch 23 : 0.46872028708457947
Average train loss of epoch 23: 0.009460117320145485
Average validation loss of epoch 23: 0.010149172259500934
Loss of batch at epoch 24 : 0.47409793734550476
Loss of batch at epoch 24 : 0.4807312786579132
Loss of batch at epoch 24 : 0.45109933614730835
Loss of batch at epoch 24 : 0.4609346389770508
Loss of batch at epoch 24 : 0.452889084815979
Loss of batch at epoch 24 : 0.45454052090644836
Loss of batch at epoch 24 : 0.4646662771701813
Loss of batch at epoch 24 : 0.4619694948196411
Loss of batch at epoch 24 : 0.4271102249622345
Loss of batch at epoch 24 : 0.45084142684936523
Loss of batch at epoch 24 : 0.46269649267196655
Loss of batch at epoch 24 : 0.47154852747917175
Loss of batch at epoch 24 : 0.4818240702152252
Loss of batch at epoch 24 : 0.48943331837654114
Loss of batch at epoch 24 : 0.4553256034851074
Loss of batch at epoch 24 : 0.41899925470352173
Loss of batch at epoch 24 : 0.4809934198856354
Loss of batch at epoch 24 : 0.4397067129611969
Loss of batch at epoch 24 : 0.47412633895874023
Loss of batch at epoch 24 : 0.4453717768192291
Loss of batch at epoch 24 : 0.49317654967308044
Loss of batch at epoch 24 : 0.4837113320827484
Loss of batch at epoch 24 : 0.45253562927246094
Loss of batch at epoch 24 : 0.4878219962120056
Loss of batch at epoch 24 : 0.511961042881012
Loss of batch at epoch 24 : 0.46790024638175964
Loss of batch at epoch 24 : 0.43834957480430603
Loss of batch at epoch 24 : 0.4509676396846771
Loss of batch at epoch 24 : 0.45243507623672485
Loss of batch at epoch 24 : 0.46424785256385803
Loss of batch at epoch 24 : 0.4791184067726135
Loss of batch at epoch 24 : 0.49389299750328064
Loss of batch at epoch 24 : 0.45300808548927307
Loss of batch at epoch 24 : 0.42604950070381165
Loss of batch at epoch 24 : 0.44162967801094055
Loss of batch at epoch 24 : 0.46841228008270264
Loss of batch at epoch 24 : 0.4655405282974243
Loss of batch at epoch 24 : 0.4421689808368683
Loss of batch at epoch 24 : 0.4581201672554016
Loss of batch at epoch 24 : 0.4567040205001831
Loss of batch at epoch 24 : 0.4625854790210724
Loss of batch at epoch 24 : 0.4768625795841217
Loss of batch at epoch 24 : 0.40118199586868286
Loss of batch at epoch 24 : 0.4543192684650421
Loss of batch at epoch 24 : 0.43327537178993225
Loss of batch at epoch 24 : 0.4401516318321228
Loss of batch at epoch 24 : 0.429026335477829
Loss of batch at epoch 24 : 0.4447062909603119
Loss of batch at epoch 24 : 0.4502769112586975
Loss of batch at epoch 24 : 0.5039997100830078
Loss of batch at epoch 24 : 0.4872318506240845
Loss of batch at epoch 24 : 0.41841650009155273
Loss of batch at epoch 24 : 0.47637906670570374
Loss of batch at epoch 24 : 0.4712926745414734
Average train loss of epoch 24: 0.009274219914636476
Average validation loss of epoch 24: 0.010301310606677123
Loss of batch at epoch 25 : 0.46665969491004944
Loss of batch at epoch 25 : 0.4567756652832031
Loss of batch at epoch 25 : 0.4674673080444336
Loss of batch at epoch 25 : 0.4482475519180298
Loss of batch at epoch 25 : 0.46582335233688354
Loss of batch at epoch 25 : 0.4596584439277649
Loss of batch at epoch 25 : 0.4688986539840698
Loss of batch at epoch 25 : 0.43950554728507996
Loss of batch at epoch 25 : 0.49179017543792725
Loss of batch at epoch 25 : 0.42928799986839294
Loss of batch at epoch 25 : 0.43868616223335266
Loss of batch at epoch 25 : 0.5093897581100464
Loss of batch at epoch 25 : 0.43573543429374695
Loss of batch at epoch 25 : 0.4151124358177185
Loss of batch at epoch 25 : 0.44334542751312256
Loss of batch at epoch 25 : 0.4535222351551056
Loss of batch at epoch 25 : 0.4750604033470154
Loss of batch at epoch 25 : 0.49900367856025696
Loss of batch at epoch 25 : 0.44946667551994324
Loss of batch at epoch 25 : 0.4993543028831482
Loss of batch at epoch 25 : 0.4237876534461975
Loss of batch at epoch 25 : 0.41681480407714844
Loss of batch at epoch 25 : 0.4584146738052368
Loss of batch at epoch 25 : 0.4592919647693634
Loss of batch at epoch 25 : 0.4545513391494751
Loss of batch at epoch 25 : 0.46155983209609985
Loss of batch at epoch 25 : 0.435933381319046
Loss of batch at epoch 25 : 0.43496838212013245
Loss of batch at epoch 25 : 0.4403563439846039
Loss of batch at epoch 25 : 0.4889149069786072
Loss of batch at epoch 25 : 0.49796512722969055
Loss of batch at epoch 25 : 0.4471740424633026
Loss of batch at epoch 25 : 0.44008877873420715
Loss of batch at epoch 25 : 0.4297236502170563
Loss of batch at epoch 25 : 0.4959786832332611
Loss of batch at epoch 25 : 0.4445614814758301
Loss of batch at epoch 25 : 0.4360942840576172
Loss of batch at epoch 25 : 0.4744890630245209
Loss of batch at epoch 25 : 0.46235162019729614
Loss of batch at epoch 25 : 0.4832479953765869
Loss of batch at epoch 25 : 0.43521741032600403
Loss of batch at epoch 25 : 0.4282955527305603
Loss of batch at epoch 25 : 0.4509236216545105
Loss of batch at epoch 25 : 0.4626327455043793
Loss of batch at epoch 25 : 0.42371970415115356
Loss of batch at epoch 25 : 0.49276185035705566
Loss of batch at epoch 25 : 0.41337791085243225
Loss of batch at epoch 25 : 0.4477342665195465
Loss of batch at epoch 25 : 0.45661696791648865
Loss of batch at epoch 25 : 0.4452199935913086
Loss of batch at epoch 25 : 0.4700528681278229
Loss of batch at epoch 25 : 0.47698065638542175
Loss of batch at epoch 25 : 0.44391798973083496
Loss of batch at epoch 25 : 0.44838544726371765
Average train loss of epoch 25: 0.00918405317743827
Average validation loss of epoch 25: 0.010098303207243331

JOB STATISTICS
==============
Job ID: 5651111
Cluster: snellius
User/Group: scur0756/scur0756
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 2-03:10:47
CPU Efficiency: 48.72% of 4-09:02:42 core-walltime
Job Wall-clock time: 05:50:09
Memory Utilized: 71.03 GB
Memory Efficiency: 19.73% of 360.00 GB
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
