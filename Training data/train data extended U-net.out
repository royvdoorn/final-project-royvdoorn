wandb: Currently logged in as: r-v-doorn1 (royvdoorn). Use `wandb login --relogin` to force relogin
/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.
  warnings.warn(
Loss of batch at epoch 1 : 3.4922709465026855
Loss of batch at epoch 1 : 3.3831984996795654
Loss of batch at epoch 1 : 3.27197265625
Loss of batch at epoch 1 : 3.201197624206543
Loss of batch at epoch 1 : 3.1547975540161133
Loss of batch at epoch 1 : 3.0768661499023438
Loss of batch at epoch 1 : 3.0292577743530273
Loss of batch at epoch 1 : 2.9891092777252197
Loss of batch at epoch 1 : 2.904709577560425
Loss of batch at epoch 1 : 2.852362871170044
Loss of batch at epoch 1 : 2.7923812866210938
Loss of batch at epoch 1 : 2.7551445960998535
Loss of batch at epoch 1 : 2.746708393096924
Loss of batch at epoch 1 : 2.6971776485443115
Loss of batch at epoch 1 : 2.60970139503479
Loss of batch at epoch 1 : 2.5927135944366455
Loss of batch at epoch 1 : 2.5751349925994873
Loss of batch at epoch 1 : 2.5180273056030273
Loss of batch at epoch 1 : 2.481006622314453
Loss of batch at epoch 1 : 2.486370801925659
Loss of batch at epoch 1 : 2.423511505126953
Loss of batch at epoch 1 : 2.4001715183258057
Loss of batch at epoch 1 : 2.376579999923706
Loss of batch at epoch 1 : 2.336920738220215
Loss of batch at epoch 1 : 2.359924793243408
Loss of batch at epoch 1 : 2.342820405960083
Loss of batch at epoch 1 : 2.3139801025390625
Loss of batch at epoch 1 : 2.2797584533691406
Loss of batch at epoch 1 : 2.259395122528076
Loss of batch at epoch 1 : 2.262223243713379
Loss of batch at epoch 1 : 2.2322628498077393
Loss of batch at epoch 1 : 2.196457862854004
Loss of batch at epoch 1 : 2.262922525405884
Loss of batch at epoch 1 : 2.1493546962738037
Loss of batch at epoch 1 : 2.174637794494629
Loss of batch at epoch 1 : 2.1452157497406006
Loss of batch at epoch 1 : 2.200531244277954
Loss of batch at epoch 1 : 2.108919858932495
Loss of batch at epoch 1 : 2.1128053665161133
Loss of batch at epoch 1 : 2.081731081008911
Loss of batch at epoch 1 : 2.1048572063446045
Loss of batch at epoch 1 : 2.0853052139282227
Loss of batch at epoch 1 : 2.032390832901001
Loss of batch at epoch 1 : 2.039874792098999
Loss of batch at epoch 1 : 2.026296615600586
Loss of batch at epoch 1 : 1.9965403079986572
Loss of batch at epoch 1 : 2.0409348011016846
Loss of batch at epoch 1 : 1.997847557067871
Loss of batch at epoch 1 : 2.033182144165039
Loss of batch at epoch 1 : 2.031916618347168
Loss of batch at epoch 1 : 1.9477083683013916
Loss of batch at epoch 1 : 1.927760124206543
Loss of batch at epoch 1 : 1.958943486213684
Loss of batch at epoch 1 : 1.9004498720169067
Average train loss of epoch 1: 0.048825333063240994
Average validation loss of epoch 1: 0.03879874964755794
Loss of batch at epoch 2 : 1.886946678161621
Loss of batch at epoch 2 : 1.9411462545394897
Loss of batch at epoch 2 : 1.9575084447860718
Loss of batch at epoch 2 : 1.8986648321151733
Loss of batch at epoch 2 : 1.8860214948654175
Loss of batch at epoch 2 : 1.9140384197235107
Loss of batch at epoch 2 : 1.8438761234283447
Loss of batch at epoch 2 : 1.8814361095428467
Loss of batch at epoch 2 : 1.8694443702697754
Loss of batch at epoch 2 : 1.9047521352767944
Loss of batch at epoch 2 : 1.8452956676483154
Loss of batch at epoch 2 : 1.8448749780654907
Loss of batch at epoch 2 : 1.8405015468597412
Loss of batch at epoch 2 : 1.81605064868927
Loss of batch at epoch 2 : 1.862581491470337
Loss of batch at epoch 2 : 1.8486980199813843
Loss of batch at epoch 2 : 1.863704800605774
Loss of batch at epoch 2 : 1.8054358959197998
Loss of batch at epoch 2 : 1.8217735290527344
Loss of batch at epoch 2 : 1.8471921682357788
Loss of batch at epoch 2 : 1.7857091426849365
Loss of batch at epoch 2 : 1.8622150421142578
Loss of batch at epoch 2 : 1.8116225004196167
Loss of batch at epoch 2 : 1.7875888347625732
Loss of batch at epoch 2 : 1.8039101362228394
Loss of batch at epoch 2 : 1.7215933799743652
Loss of batch at epoch 2 : 1.8225922584533691
Loss of batch at epoch 2 : 1.8135284185409546
Loss of batch at epoch 2 : 1.7813613414764404
Loss of batch at epoch 2 : 1.7399009466171265
Loss of batch at epoch 2 : 1.7232739925384521
Loss of batch at epoch 2 : 1.7262409925460815
Loss of batch at epoch 2 : 1.7799121141433716
Loss of batch at epoch 2 : 1.7372187376022339
Loss of batch at epoch 2 : 1.7086788415908813
Loss of batch at epoch 2 : 1.6904082298278809
Loss of batch at epoch 2 : 1.7298572063446045
Loss of batch at epoch 2 : 1.6864838600158691
Loss of batch at epoch 2 : 1.6879522800445557
Loss of batch at epoch 2 : 1.7134323120117188
Loss of batch at epoch 2 : 1.7184134721755981
Loss of batch at epoch 2 : 1.6920005083084106
Loss of batch at epoch 2 : 1.6579489707946777
Loss of batch at epoch 2 : 1.7223032712936401
Loss of batch at epoch 2 : 1.7272820472717285
Loss of batch at epoch 2 : 1.6675686836242676
Loss of batch at epoch 2 : 1.6386497020721436
Loss of batch at epoch 2 : 1.6117026805877686
Loss of batch at epoch 2 : 1.660831093788147
Loss of batch at epoch 2 : 1.6593847274780273
Loss of batch at epoch 2 : 1.6663012504577637
Loss of batch at epoch 2 : 1.6449532508850098
Loss of batch at epoch 2 : 1.6386908292770386
Loss of batch at epoch 2 : 1.7235151529312134
Average train loss of epoch 2: 0.03581888485168502
Average validation loss of epoch 2: 0.03279440330736565
Loss of batch at epoch 3 : 1.6038322448730469
Loss of batch at epoch 3 : 1.6254962682724
Loss of batch at epoch 3 : 1.6268861293792725
Loss of batch at epoch 3 : 1.6423883438110352
Loss of batch at epoch 3 : 1.6082054376602173
Loss of batch at epoch 3 : 1.598564863204956
Loss of batch at epoch 3 : 1.6261035203933716
Loss of batch at epoch 3 : 1.6052958965301514
Loss of batch at epoch 3 : 1.5674259662628174
Loss of batch at epoch 3 : 1.601165771484375
Loss of batch at epoch 3 : 1.5698434114456177
Loss of batch at epoch 3 : 1.5880316495895386
Loss of batch at epoch 3 : 1.5676137208938599
Loss of batch at epoch 3 : 1.56112802028656
Loss of batch at epoch 3 : 1.5756876468658447
Loss of batch at epoch 3 : 1.5428005456924438
Loss of batch at epoch 3 : 1.5518654584884644
Loss of batch at epoch 3 : 1.5249958038330078
Loss of batch at epoch 3 : 1.5512360334396362
Loss of batch at epoch 3 : 1.614385962486267
Loss of batch at epoch 3 : 1.5689125061035156
Loss of batch at epoch 3 : 1.4904162883758545
Loss of batch at epoch 3 : 1.5505932569503784
Loss of batch at epoch 3 : 1.52524995803833
Loss of batch at epoch 3 : 1.4934031963348389
Loss of batch at epoch 3 : 1.5073741674423218
Loss of batch at epoch 3 : 1.5113914012908936
Loss of batch at epoch 3 : 1.4527736902236938
Loss of batch at epoch 3 : 1.495683193206787
Loss of batch at epoch 3 : 1.5063129663467407
Loss of batch at epoch 3 : 1.5168153047561646
Loss of batch at epoch 3 : 1.4430701732635498
Loss of batch at epoch 3 : 1.47057044506073
Loss of batch at epoch 3 : 1.4872205257415771
Loss of batch at epoch 3 : 1.440629482269287
Loss of batch at epoch 3 : 1.525911569595337
Loss of batch at epoch 3 : 1.4653375148773193
Loss of batch at epoch 3 : 1.4392008781433105
Loss of batch at epoch 3 : 1.4313431978225708
Loss of batch at epoch 3 : 1.430971384048462
Loss of batch at epoch 3 : 1.4394365549087524
Loss of batch at epoch 3 : 1.4665800333023071
Loss of batch at epoch 3 : 1.4369235038757324
Loss of batch at epoch 3 : 1.4452145099639893
Loss of batch at epoch 3 : 1.4273955821990967
Loss of batch at epoch 3 : 1.431348443031311
Loss of batch at epoch 3 : 1.4387879371643066
Loss of batch at epoch 3 : 1.494640827178955
Loss of batch at epoch 3 : 1.4325257539749146
Loss of batch at epoch 3 : 1.4015852212905884
Loss of batch at epoch 3 : 1.4143275022506714
Loss of batch at epoch 3 : 1.4540750980377197
Loss of batch at epoch 3 : 1.4404221773147583
Loss of batch at epoch 3 : 1.4345219135284424
Average train loss of epoch 3: 0.030494376560749627
Average validation loss of epoch 3: 0.027972731927428583
Loss of batch at epoch 4 : 1.3953057527542114
Loss of batch at epoch 4 : 1.418188214302063
Loss of batch at epoch 4 : 1.4105250835418701
Loss of batch at epoch 4 : 1.3724348545074463
Loss of batch at epoch 4 : 1.3929879665374756
Loss of batch at epoch 4 : 1.3839068412780762
Loss of batch at epoch 4 : 1.3433637619018555
Loss of batch at epoch 4 : 1.3501895666122437
Loss of batch at epoch 4 : 1.3696722984313965
Loss of batch at epoch 4 : 1.3999444246292114
Loss of batch at epoch 4 : 1.3846666812896729
Loss of batch at epoch 4 : 1.338729739189148
Loss of batch at epoch 4 : 1.3380417823791504
Loss of batch at epoch 4 : 1.351868987083435
Loss of batch at epoch 4 : 1.3355320692062378
Loss of batch at epoch 4 : 1.364905595779419
Loss of batch at epoch 4 : 1.3359040021896362
Loss of batch at epoch 4 : 1.3094309568405151
Loss of batch at epoch 4 : 1.3582581281661987
Loss of batch at epoch 4 : 1.3543992042541504
Loss of batch at epoch 4 : 1.3603843450546265
Loss of batch at epoch 4 : 1.2889066934585571
Loss of batch at epoch 4 : 1.286530613899231
Loss of batch at epoch 4 : 1.3186827898025513
Loss of batch at epoch 4 : 1.323513388633728
Loss of batch at epoch 4 : 1.3342506885528564
Loss of batch at epoch 4 : 1.3352614641189575
Loss of batch at epoch 4 : 1.329900860786438
Loss of batch at epoch 4 : 1.2643669843673706
Loss of batch at epoch 4 : 1.3459534645080566
Loss of batch at epoch 4 : 1.315674901008606
Loss of batch at epoch 4 : 1.3503211736679077
Loss of batch at epoch 4 : 1.2184251546859741
Loss of batch at epoch 4 : 1.32696533203125
Loss of batch at epoch 4 : 1.274753451347351
Loss of batch at epoch 4 : 1.2638661861419678
Loss of batch at epoch 4 : 1.296590805053711
Loss of batch at epoch 4 : 1.2690346240997314
Loss of batch at epoch 4 : 1.2589205503463745
Loss of batch at epoch 4 : 1.234427571296692
Loss of batch at epoch 4 : 1.230400562286377
Loss of batch at epoch 4 : 1.2505912780761719
Loss of batch at epoch 4 : 1.2671115398406982
Loss of batch at epoch 4 : 1.2340141534805298
Loss of batch at epoch 4 : 1.2393746376037598
Loss of batch at epoch 4 : 1.2699226140975952
Loss of batch at epoch 4 : 1.3065898418426514
Loss of batch at epoch 4 : 1.292822241783142
Loss of batch at epoch 4 : 1.2186402082443237
Loss of batch at epoch 4 : 1.2506308555603027
Loss of batch at epoch 4 : 1.2022297382354736
Loss of batch at epoch 4 : 1.2228832244873047
Loss of batch at epoch 4 : 1.2330273389816284
Loss of batch at epoch 4 : 1.236492395401001
Average train loss of epoch 4: 0.0264226017468362
Average validation loss of epoch 4: 0.024184287999214148
Loss of batch at epoch 5 : 1.238846778869629
Loss of batch at epoch 5 : 1.1905616521835327
Loss of batch at epoch 5 : 1.1743738651275635
Loss of batch at epoch 5 : 1.1852777004241943
Loss of batch at epoch 5 : 1.2045973539352417
Loss of batch at epoch 5 : 1.2214055061340332
Loss of batch at epoch 5 : 1.2073922157287598
Loss of batch at epoch 5 : 1.2024394273757935
Loss of batch at epoch 5 : 1.1918047666549683
Loss of batch at epoch 5 : 1.173272728919983
Loss of batch at epoch 5 : 1.172684907913208
Loss of batch at epoch 5 : 1.1027467250823975
Loss of batch at epoch 5 : 1.1568050384521484
Loss of batch at epoch 5 : 1.1750808954238892
Loss of batch at epoch 5 : 1.1465414762496948
Loss of batch at epoch 5 : 1.1613000631332397
Loss of batch at epoch 5 : 1.167967438697815
Loss of batch at epoch 5 : 1.1707797050476074
Loss of batch at epoch 5 : 1.165276050567627
Loss of batch at epoch 5 : 1.1230214834213257
Loss of batch at epoch 5 : 1.1200717687606812
Loss of batch at epoch 5 : 1.1300921440124512
Loss of batch at epoch 5 : 1.1477587223052979
Loss of batch at epoch 5 : 1.1509475708007812
Loss of batch at epoch 5 : 1.1679635047912598
Loss of batch at epoch 5 : 1.1212384700775146
Loss of batch at epoch 5 : 1.1779870986938477
Loss of batch at epoch 5 : 1.1247621774673462
Loss of batch at epoch 5 : 1.1178860664367676
Loss of batch at epoch 5 : 1.1527483463287354
Loss of batch at epoch 5 : 1.1434450149536133
Loss of batch at epoch 5 : 1.1334856748580933
Loss of batch at epoch 5 : 1.149958848953247
Loss of batch at epoch 5 : 1.1743924617767334
Loss of batch at epoch 5 : 1.1503647565841675
Loss of batch at epoch 5 : 1.0959484577178955
Loss of batch at epoch 5 : 1.1298679113388062
Loss of batch at epoch 5 : 1.1240684986114502
Loss of batch at epoch 5 : 1.1049634218215942
Loss of batch at epoch 5 : 1.1319761276245117
Loss of batch at epoch 5 : 1.116817593574524
Loss of batch at epoch 5 : 1.110135555267334
Loss of batch at epoch 5 : 1.08200204372406
Loss of batch at epoch 5 : 1.0841411352157593
Loss of batch at epoch 5 : 1.08334219455719
Loss of batch at epoch 5 : 1.127869725227356
Loss of batch at epoch 5 : 1.087335467338562
Loss of batch at epoch 5 : 1.061928629875183
Loss of batch at epoch 5 : 1.1140549182891846
Loss of batch at epoch 5 : 1.078891634941101
Loss of batch at epoch 5 : 1.0870198011398315
Loss of batch at epoch 5 : 1.0612425804138184
Loss of batch at epoch 5 : 1.0270655155181885
Loss of batch at epoch 5 : 1.0890533924102783
Average train loss of epoch 5: 0.022962285298923666
Average validation loss of epoch 5: 0.021524830699368357
Loss of batch at epoch 6 : 1.0908045768737793
Loss of batch at epoch 6 : 1.030585527420044
Loss of batch at epoch 6 : 1.0646498203277588
Loss of batch at epoch 6 : 1.0939445495605469
Loss of batch at epoch 6 : 1.0560301542282104
Loss of batch at epoch 6 : 1.080986499786377
Loss of batch at epoch 6 : 1.0384293794631958
Loss of batch at epoch 6 : 1.0962929725646973
Loss of batch at epoch 6 : 1.083019733428955
Loss of batch at epoch 6 : 1.000415325164795
Loss of batch at epoch 6 : 1.083489179611206
Loss of batch at epoch 6 : 1.0510371923446655
Loss of batch at epoch 6 : 1.087916612625122
Loss of batch at epoch 6 : 1.011347770690918
Loss of batch at epoch 6 : 1.0205316543579102
Loss of batch at epoch 6 : 1.0855903625488281
Loss of batch at epoch 6 : 1.0504308938980103
Loss of batch at epoch 6 : 1.030739426612854
Loss of batch at epoch 6 : 1.028463363647461
Loss of batch at epoch 6 : 1.0541800260543823
Loss of batch at epoch 6 : 1.0103703737258911
Loss of batch at epoch 6 : 0.9800718426704407
Loss of batch at epoch 6 : 1.045170545578003
Loss of batch at epoch 6 : 0.9992804527282715
Loss of batch at epoch 6 : 1.039157748222351
Loss of batch at epoch 6 : 0.9961159229278564
Loss of batch at epoch 6 : 1.0056644678115845
Loss of batch at epoch 6 : 1.0171655416488647
Loss of batch at epoch 6 : 1.0629769563674927
Loss of batch at epoch 6 : 1.0187606811523438
Loss of batch at epoch 6 : 1.1277059316635132
Loss of batch at epoch 6 : 1.022310733795166
Loss of batch at epoch 6 : 1.052100419998169
Loss of batch at epoch 6 : 0.9822364449501038
Loss of batch at epoch 6 : 1.036989688873291
Loss of batch at epoch 6 : 1.0706067085266113
Loss of batch at epoch 6 : 0.9995104670524597
Loss of batch at epoch 6 : 1.0468249320983887
Loss of batch at epoch 6 : 0.9966404438018799
Loss of batch at epoch 6 : 0.9886758327484131
Loss of batch at epoch 6 : 0.984541118144989
Loss of batch at epoch 6 : 1.0064446926116943
Loss of batch at epoch 6 : 0.9732233285903931
Loss of batch at epoch 6 : 0.9794755578041077
Loss of batch at epoch 6 : 0.9725145101547241
Loss of batch at epoch 6 : 1.0073546171188354
Loss of batch at epoch 6 : 0.9855298399925232
Loss of batch at epoch 6 : 0.9831815958023071
Loss of batch at epoch 6 : 0.9853491187095642
Loss of batch at epoch 6 : 0.9847757816314697
Loss of batch at epoch 6 : 1.022323727607727
Loss of batch at epoch 6 : 0.9788074493408203
Loss of batch at epoch 6 : 0.9556937217712402
Loss of batch at epoch 6 : 1.1171053647994995
Average train loss of epoch 6: 0.020751883326581025
Average validation loss of epoch 6: 0.019864490136554346
Loss of batch at epoch 7 : 1.010280728340149
Loss of batch at epoch 7 : 0.9933065176010132
Loss of batch at epoch 7 : 1.0020111799240112
Loss of batch at epoch 7 : 0.937682569026947
Loss of batch at epoch 7 : 0.9958036541938782
Loss of batch at epoch 7 : 0.9609625339508057
Loss of batch at epoch 7 : 0.934820830821991
Loss of batch at epoch 7 : 1.0154340267181396
Loss of batch at epoch 7 : 0.9353451132774353
Loss of batch at epoch 7 : 0.9262942671775818
Loss of batch at epoch 7 : 1.0186842679977417
Loss of batch at epoch 7 : 0.9984427094459534
Loss of batch at epoch 7 : 0.9237326383590698
Loss of batch at epoch 7 : 0.9671356678009033
Loss of batch at epoch 7 : 0.9817004203796387
Loss of batch at epoch 7 : 1.0166734457015991
Loss of batch at epoch 7 : 0.9918695688247681
Loss of batch at epoch 7 : 0.9502125978469849
Loss of batch at epoch 7 : 1.003461480140686
Loss of batch at epoch 7 : 0.9706227779388428
Loss of batch at epoch 7 : 0.9935793280601501
Loss of batch at epoch 7 : 0.9451094269752502
Loss of batch at epoch 7 : 0.9861127734184265
Loss of batch at epoch 7 : 0.9565625190734863
Loss of batch at epoch 7 : 0.904101550579071
Loss of batch at epoch 7 : 0.9494137763977051
Loss of batch at epoch 7 : 0.9711819291114807
Loss of batch at epoch 7 : 0.8895954489707947
Loss of batch at epoch 7 : 0.9199181199073792
Loss of batch at epoch 7 : 0.9528898596763611
Loss of batch at epoch 7 : 0.9505422115325928
Loss of batch at epoch 7 : 0.9275619387626648
Loss of batch at epoch 7 : 0.9201272130012512
Loss of batch at epoch 7 : 0.8851000070571899
Loss of batch at epoch 7 : 0.9105222821235657
Loss of batch at epoch 7 : 0.946300745010376
Loss of batch at epoch 7 : 0.9094318151473999
Loss of batch at epoch 7 : 0.9495297074317932
Loss of batch at epoch 7 : 0.9020174145698547
Loss of batch at epoch 7 : 0.9002801775932312
Loss of batch at epoch 7 : 0.9212471842765808
Loss of batch at epoch 7 : 0.8844987750053406
Loss of batch at epoch 7 : 0.9185988306999207
Loss of batch at epoch 7 : 0.8729432225227356
Loss of batch at epoch 7 : 0.8690170645713806
Loss of batch at epoch 7 : 0.9106600880622864
Loss of batch at epoch 7 : 0.944017231464386
Loss of batch at epoch 7 : 0.8832607865333557
Loss of batch at epoch 7 : 0.8855375051498413
Loss of batch at epoch 7 : 0.8749769926071167
Loss of batch at epoch 7 : 0.9511927366256714
Loss of batch at epoch 7 : 0.8636298179626465
Loss of batch at epoch 7 : 0.8923319578170776
Loss of batch at epoch 7 : 0.8800276517868042
Average train loss of epoch 7: 0.018953058415157212
Average validation loss of epoch 7: 0.01781848785451767
Loss of batch at epoch 8 : 0.8793097138404846
Loss of batch at epoch 8 : 0.8502986431121826
Loss of batch at epoch 8 : 0.8751635551452637
Loss of batch at epoch 8 : 0.9014245271682739
Loss of batch at epoch 8 : 0.9159641265869141
Loss of batch at epoch 8 : 0.8507972359657288
Loss of batch at epoch 8 : 0.8787152767181396
Loss of batch at epoch 8 : 0.8541681170463562
Loss of batch at epoch 8 : 0.8572020530700684
Loss of batch at epoch 8 : 0.8816595077514648
Loss of batch at epoch 8 : 0.8425952196121216
Loss of batch at epoch 8 : 0.8432856798171997
Loss of batch at epoch 8 : 0.8851256966590881
Loss of batch at epoch 8 : 0.9181522130966187
Loss of batch at epoch 8 : 0.8473758697509766
Loss of batch at epoch 8 : 0.8458312153816223
Loss of batch at epoch 8 : 0.880054771900177
Loss of batch at epoch 8 : 0.8782886862754822
Loss of batch at epoch 8 : 0.8951253294944763
Loss of batch at epoch 8 : 0.82750403881073
Loss of batch at epoch 8 : 0.8292824625968933
Loss of batch at epoch 8 : 0.8157970905303955
Loss of batch at epoch 8 : 0.847851037979126
Loss of batch at epoch 8 : 0.8665361404418945
Loss of batch at epoch 8 : 0.8281184434890747
Loss of batch at epoch 8 : 0.8794036507606506
Loss of batch at epoch 8 : 0.8482794761657715
Loss of batch at epoch 8 : 0.8704700469970703
Loss of batch at epoch 8 : 0.8467704057693481
Loss of batch at epoch 8 : 0.7876884341239929
Loss of batch at epoch 8 : 0.872107982635498
Loss of batch at epoch 8 : 0.8546003103256226
Loss of batch at epoch 8 : 0.7790945768356323
Loss of batch at epoch 8 : 0.8705535531044006
Loss of batch at epoch 8 : 0.8818050026893616
Loss of batch at epoch 8 : 0.8822336196899414
Loss of batch at epoch 8 : 0.8364911079406738
Loss of batch at epoch 8 : 0.7923126220703125
Loss of batch at epoch 8 : 0.8010171055793762
Loss of batch at epoch 8 : 0.826160728931427
Loss of batch at epoch 8 : 0.8722832798957825
Loss of batch at epoch 8 : 0.8402913212776184
Loss of batch at epoch 8 : 0.8342701196670532
Loss of batch at epoch 8 : 0.7639589309692383
Loss of batch at epoch 8 : 0.8413342237472534
Loss of batch at epoch 8 : 0.8137355446815491
Loss of batch at epoch 8 : 0.8442578911781311
Loss of batch at epoch 8 : 0.8429134488105774
Loss of batch at epoch 8 : 0.7892512679100037
Loss of batch at epoch 8 : 0.7643082737922668
Loss of batch at epoch 8 : 0.8556791543960571
Loss of batch at epoch 8 : 0.8097429871559143
Loss of batch at epoch 8 : 0.8331224322319031
Loss of batch at epoch 8 : 0.8316751718521118
Average train loss of epoch 8: 0.017087916458961766
Average validation loss of epoch 8: 0.01630760603882247
Loss of batch at epoch 9 : 0.8495681881904602
Loss of batch at epoch 9 : 0.8025654554367065
Loss of batch at epoch 9 : 0.7796057462692261
Loss of batch at epoch 9 : 0.7967177033424377
Loss of batch at epoch 9 : 0.7822439670562744
Loss of batch at epoch 9 : 0.7702639698982239
Loss of batch at epoch 9 : 0.753950834274292
Loss of batch at epoch 9 : 0.7895107865333557
Loss of batch at epoch 9 : 0.8034582734107971
Loss of batch at epoch 9 : 0.7747015357017517
Loss of batch at epoch 9 : 0.8222876787185669
Loss of batch at epoch 9 : 0.7935826778411865
Loss of batch at epoch 9 : 0.7385688424110413
Loss of batch at epoch 9 : 0.7537928819656372
Loss of batch at epoch 9 : 0.7436530590057373
Loss of batch at epoch 9 : 0.7668427228927612
Loss of batch at epoch 9 : 0.8470975160598755
Loss of batch at epoch 9 : 0.7640939354896545
Loss of batch at epoch 9 : 0.8269261717796326
Loss of batch at epoch 9 : 0.8575652241706848
Loss of batch at epoch 9 : 0.7603226900100708
Loss of batch at epoch 9 : 0.7626664042472839
Loss of batch at epoch 9 : 0.7824440598487854
Loss of batch at epoch 9 : 0.7905400991439819
Loss of batch at epoch 9 : 0.7479594945907593
Loss of batch at epoch 9 : 0.8007619976997375
Loss of batch at epoch 9 : 0.7834224700927734
Loss of batch at epoch 9 : 0.7724933624267578
Loss of batch at epoch 9 : 0.7541781663894653
Loss of batch at epoch 9 : 0.8223311305046082
Loss of batch at epoch 9 : 0.8322654366493225
Loss of batch at epoch 9 : 0.789013147354126
Loss of batch at epoch 9 : 0.7799454927444458
Loss of batch at epoch 9 : 0.795075535774231
Loss of batch at epoch 9 : 0.7970070838928223
Loss of batch at epoch 9 : 0.8021722435951233
Loss of batch at epoch 9 : 0.7496811747550964
Loss of batch at epoch 9 : 0.7758099436759949
Loss of batch at epoch 9 : 0.7874003052711487
Loss of batch at epoch 9 : 0.7884925007820129
Loss of batch at epoch 9 : 0.8103163242340088
Loss of batch at epoch 9 : 0.785194993019104
Loss of batch at epoch 9 : 0.786716639995575
Loss of batch at epoch 9 : 0.8207510709762573
Loss of batch at epoch 9 : 0.7465947866439819
Loss of batch at epoch 9 : 0.7497660517692566
Loss of batch at epoch 9 : 0.8115156292915344
Loss of batch at epoch 9 : 0.7856175303459167
Loss of batch at epoch 9 : 0.7490989565849304
Loss of batch at epoch 9 : 0.7341992259025574
Loss of batch at epoch 9 : 0.7752598524093628
Loss of batch at epoch 9 : 0.7441951632499695
Loss of batch at epoch 9 : 0.7885141968727112
Loss of batch at epoch 9 : 0.7251800894737244
Average train loss of epoch 9: 0.01579682803848415
Average validation loss of epoch 9: 0.015105168827455051
Loss of batch at epoch 10 : 0.7902331352233887
Loss of batch at epoch 10 : 0.7791277766227722
Loss of batch at epoch 10 : 0.7447260618209839
Loss of batch at epoch 10 : 0.7250158786773682
Loss of batch at epoch 10 : 0.7618772387504578
Loss of batch at epoch 10 : 0.7907281517982483
Loss of batch at epoch 10 : 0.7337762713432312
Loss of batch at epoch 10 : 0.7395007610321045
Loss of batch at epoch 10 : 0.7652162909507751
Loss of batch at epoch 10 : 0.7683628797531128
Loss of batch at epoch 10 : 0.7162841558456421
Loss of batch at epoch 10 : 0.7764484882354736
Loss of batch at epoch 10 : 0.7668539881706238
Loss of batch at epoch 10 : 0.7177240252494812
Loss of batch at epoch 10 : 0.7338873744010925
Loss of batch at epoch 10 : 0.744952917098999
Loss of batch at epoch 10 : 0.7653432488441467
Loss of batch at epoch 10 : 0.7273864150047302
Loss of batch at epoch 10 : 0.7222312688827515
Loss of batch at epoch 10 : 0.7498719096183777
Loss of batch at epoch 10 : 0.7966201901435852
Loss of batch at epoch 10 : 0.7627435922622681
Loss of batch at epoch 10 : 0.7909224033355713
Loss of batch at epoch 10 : 0.7090103030204773
Loss of batch at epoch 10 : 0.6987221837043762
Loss of batch at epoch 10 : 0.7271007299423218
Loss of batch at epoch 10 : 0.7209362983703613
Loss of batch at epoch 10 : 0.7356346845626831
Loss of batch at epoch 10 : 0.7191182971000671
Loss of batch at epoch 10 : 0.74434894323349
Loss of batch at epoch 10 : 0.7660282254219055
Loss of batch at epoch 10 : 0.6898086071014404
Loss of batch at epoch 10 : 0.7123034596443176
Loss of batch at epoch 10 : 0.6806438565254211
Loss of batch at epoch 10 : 0.7015230059623718
Loss of batch at epoch 10 : 0.7535626292228699
Loss of batch at epoch 10 : 0.7655885815620422
Loss of batch at epoch 10 : 0.6728740930557251
Loss of batch at epoch 10 : 0.679018497467041
Loss of batch at epoch 10 : 0.7239236235618591
Loss of batch at epoch 10 : 0.6887754797935486
Loss of batch at epoch 10 : 0.7587912678718567
Loss of batch at epoch 10 : 0.6504959464073181
Loss of batch at epoch 10 : 0.7040629386901855
Loss of batch at epoch 10 : 0.7299395203590393
Loss of batch at epoch 10 : 0.7743646502494812
Loss of batch at epoch 10 : 0.6835981607437134
Loss of batch at epoch 10 : 0.7058506011962891
Loss of batch at epoch 10 : 0.6851639151573181
Loss of batch at epoch 10 : 0.7612549066543579
Loss of batch at epoch 10 : 0.7420214414596558
Loss of batch at epoch 10 : 0.6815170645713806
Loss of batch at epoch 10 : 0.6971782445907593
Loss of batch at epoch 10 : 0.6262431740760803
Average train loss of epoch 10: 0.014734590115878366
Average validation loss of epoch 10: 0.014256202813350794
Loss of batch at epoch 11 : 0.6991948485374451
Loss of batch at epoch 11 : 0.7126317024230957
Loss of batch at epoch 11 : 0.6635346412658691
Loss of batch at epoch 11 : 0.7059438228607178
Loss of batch at epoch 11 : 0.7046748399734497
Loss of batch at epoch 11 : 0.7245541214942932
Loss of batch at epoch 11 : 0.7140932679176331
Loss of batch at epoch 11 : 0.6981967687606812
Loss of batch at epoch 11 : 0.6620145440101624
Loss of batch at epoch 11 : 0.6809629201889038
Loss of batch at epoch 11 : 0.6893377900123596
Loss of batch at epoch 11 : 0.6656149625778198
Loss of batch at epoch 11 : 0.7273238897323608
Loss of batch at epoch 11 : 0.6622187495231628
Loss of batch at epoch 11 : 0.6658323407173157
Loss of batch at epoch 11 : 0.7045801281929016
Loss of batch at epoch 11 : 0.741533637046814
Loss of batch at epoch 11 : 0.6909269690513611
Loss of batch at epoch 11 : 0.7092824578285217
Loss of batch at epoch 11 : 0.6670542359352112
Loss of batch at epoch 11 : 0.7021017670631409
Loss of batch at epoch 11 : 0.7272682785987854
Loss of batch at epoch 11 : 0.6554120779037476
Loss of batch at epoch 11 : 0.7485111355781555
Loss of batch at epoch 11 : 0.7181928753852844
Loss of batch at epoch 11 : 0.7197204232215881
Loss of batch at epoch 11 : 0.7121831178665161
Loss of batch at epoch 11 : 0.7104315757751465
Loss of batch at epoch 11 : 0.6903595924377441
Loss of batch at epoch 11 : 0.7610292434692383
Loss of batch at epoch 11 : 0.6888097524642944
Loss of batch at epoch 11 : 0.7484237551689148
Loss of batch at epoch 11 : 0.6726498007774353
Loss of batch at epoch 11 : 0.7171416878700256
Loss of batch at epoch 11 : 0.7777871489524841
Loss of batch at epoch 11 : 0.6792012453079224
Loss of batch at epoch 11 : 0.6913989186286926
Loss of batch at epoch 11 : 0.6837143301963806
Loss of batch at epoch 11 : 0.7049212455749512
Loss of batch at epoch 11 : 0.6862971782684326
Loss of batch at epoch 11 : 0.6658342480659485
Loss of batch at epoch 11 : 0.695688784122467
Loss of batch at epoch 11 : 0.6725441813468933
Loss of batch at epoch 11 : 0.7074646949768066
Loss of batch at epoch 11 : 0.6530566811561584
Loss of batch at epoch 11 : 0.6463319659233093
Loss of batch at epoch 11 : 0.718879222869873
Loss of batch at epoch 11 : 0.709227979183197
Loss of batch at epoch 11 : 0.6967296600341797
Loss of batch at epoch 11 : 0.7132833003997803
Loss of batch at epoch 11 : 0.6733248233795166
Loss of batch at epoch 11 : 0.6612600088119507
Loss of batch at epoch 11 : 0.6593726277351379
Loss of batch at epoch 11 : 0.7329649925231934
Average train loss of epoch 11: 0.014074319863693317
Average validation loss of epoch 11: 0.013546041366628524
Loss of batch at epoch 12 : 0.683652400970459
Loss of batch at epoch 12 : 0.667029857635498
Loss of batch at epoch 12 : 0.6788679361343384
Loss of batch at epoch 12 : 0.6541867256164551
Loss of batch at epoch 12 : 0.6756219863891602
Loss of batch at epoch 12 : 0.6309945583343506
Loss of batch at epoch 12 : 0.684773862361908
Loss of batch at epoch 12 : 0.6595779657363892
Loss of batch at epoch 12 : 0.6113901734352112
Loss of batch at epoch 12 : 0.6944931745529175
Loss of batch at epoch 12 : 0.647689700126648
Loss of batch at epoch 12 : 0.6332675814628601
Loss of batch at epoch 12 : 0.7258682250976562
Loss of batch at epoch 12 : 0.6486850380897522
Loss of batch at epoch 12 : 0.6722157001495361
Loss of batch at epoch 12 : 0.6940656900405884
Loss of batch at epoch 12 : 0.6190391182899475
Loss of batch at epoch 12 : 0.6534826159477234
Loss of batch at epoch 12 : 0.6534928679466248
Loss of batch at epoch 12 : 0.6390854120254517
Loss of batch at epoch 12 : 0.724317729473114
Loss of batch at epoch 12 : 0.6023884415626526
Loss of batch at epoch 12 : 0.6563187837600708
Loss of batch at epoch 12 : 0.6877062320709229
Loss of batch at epoch 12 : 0.6488503813743591
Loss of batch at epoch 12 : 0.6541078686714172
Loss of batch at epoch 12 : 0.6595555543899536
Loss of batch at epoch 12 : 0.6195788383483887
Loss of batch at epoch 12 : 0.6917910575866699
Loss of batch at epoch 12 : 0.665126621723175
Loss of batch at epoch 12 : 0.6322678327560425
Loss of batch at epoch 12 : 0.6868605613708496
Loss of batch at epoch 12 : 0.6269070506095886
Loss of batch at epoch 12 : 0.623532772064209
Loss of batch at epoch 12 : 0.6463837623596191
Loss of batch at epoch 12 : 0.6751024723052979
Loss of batch at epoch 12 : 0.639013946056366
Loss of batch at epoch 12 : 0.6543303728103638
Loss of batch at epoch 12 : 0.6119507551193237
Loss of batch at epoch 12 : 0.6205394268035889
Loss of batch at epoch 12 : 0.6403895616531372
Loss of batch at epoch 12 : 0.6054205894470215
Loss of batch at epoch 12 : 0.6847596168518066
Loss of batch at epoch 12 : 0.6458258032798767
Loss of batch at epoch 12 : 0.6498413681983948
Loss of batch at epoch 12 : 0.6647228002548218
Loss of batch at epoch 12 : 0.6229209899902344
Loss of batch at epoch 12 : 0.7150261998176575
Loss of batch at epoch 12 : 0.583999752998352
Loss of batch at epoch 12 : 0.6066209673881531
Loss of batch at epoch 12 : 0.6724804043769836
Loss of batch at epoch 12 : 0.6525733470916748
Loss of batch at epoch 12 : 0.6149260997772217
Loss of batch at epoch 12 : 0.6252460479736328
Average train loss of epoch 12: 0.013158651498647837
Average validation loss of epoch 12: 0.012964548888029876
Loss of batch at epoch 13 : 0.6584614515304565
Loss of batch at epoch 13 : 0.7004808783531189
Loss of batch at epoch 13 : 0.6252686381340027
Loss of batch at epoch 13 : 0.657697319984436
Loss of batch at epoch 13 : 0.5922830104827881
Loss of batch at epoch 13 : 0.5949565768241882
Loss of batch at epoch 13 : 0.6849728226661682
Loss of batch at epoch 13 : 0.5773981809616089
Loss of batch at epoch 13 : 0.6088547706604004
Loss of batch at epoch 13 : 0.6204810738563538
Loss of batch at epoch 13 : 0.6325224041938782
Loss of batch at epoch 13 : 0.6184481978416443
Loss of batch at epoch 13 : 0.5999553203582764
Loss of batch at epoch 13 : 0.5925091505050659
Loss of batch at epoch 13 : 0.6074251532554626
Loss of batch at epoch 13 : 0.6426563262939453
Loss of batch at epoch 13 : 0.5893816947937012
Loss of batch at epoch 13 : 0.6044076085090637
Loss of batch at epoch 13 : 0.6411049962043762
Loss of batch at epoch 13 : 0.620496928691864
Loss of batch at epoch 13 : 0.6032977104187012
Loss of batch at epoch 13 : 0.5696892738342285
Loss of batch at epoch 13 : 0.6240584254264832
Loss of batch at epoch 13 : 0.60328209400177
Loss of batch at epoch 13 : 0.6277741193771362
Loss of batch at epoch 13 : 0.6599625945091248
Loss of batch at epoch 13 : 0.6367360353469849
Loss of batch at epoch 13 : 0.6313108801841736
Loss of batch at epoch 13 : 0.6091927289962769
Loss of batch at epoch 13 : 0.5976382493972778
Loss of batch at epoch 13 : 0.6265920996665955
Loss of batch at epoch 13 : 0.6458929777145386
Loss of batch at epoch 13 : 0.6180630326271057
Loss of batch at epoch 13 : 0.5957809686660767
Loss of batch at epoch 13 : 0.6056309342384338
Loss of batch at epoch 13 : 0.6241538524627686
Loss of batch at epoch 13 : 0.6988445520401001
Loss of batch at epoch 13 : 0.6016618609428406
Loss of batch at epoch 13 : 0.5768918991088867
Loss of batch at epoch 13 : 0.6647944450378418
Loss of batch at epoch 13 : 0.6676105260848999
Loss of batch at epoch 13 : 0.580331563949585
Loss of batch at epoch 13 : 0.6556081771850586
Loss of batch at epoch 13 : 0.6220183968544006
Loss of batch at epoch 13 : 0.6098498106002808
Loss of batch at epoch 13 : 0.5908707976341248
Loss of batch at epoch 13 : 0.6303908228874207
Loss of batch at epoch 13 : 0.6890841722488403
Loss of batch at epoch 13 : 0.6156532764434814
Loss of batch at epoch 13 : 0.6118990778923035
Loss of batch at epoch 13 : 0.5851823091506958
Loss of batch at epoch 13 : 0.6028158068656921
Loss of batch at epoch 13 : 0.5444915890693665
Loss of batch at epoch 13 : 0.5718175172805786
Average train loss of epoch 13: 0.012497623435056771
Average validation loss of epoch 13: 0.012324797986733794
Loss of batch at epoch 14 : 0.5919541120529175
Loss of batch at epoch 14 : 0.6195752024650574
Loss of batch at epoch 14 : 0.6264800429344177
Loss of batch at epoch 14 : 0.6051506996154785
Loss of batch at epoch 14 : 0.6078853607177734
Loss of batch at epoch 14 : 0.6297152638435364
Loss of batch at epoch 14 : 0.5713311433792114
Loss of batch at epoch 14 : 0.5846251249313354
Loss of batch at epoch 14 : 0.6040348410606384
Loss of batch at epoch 14 : 0.6171339154243469
Loss of batch at epoch 14 : 0.5945687294006348
Loss of batch at epoch 14 : 0.6297600865364075
Loss of batch at epoch 14 : 0.6076584458351135
Loss of batch at epoch 14 : 0.5823242664337158
Loss of batch at epoch 14 : 0.6321345567703247
Loss of batch at epoch 14 : 0.5965176224708557
Loss of batch at epoch 14 : 0.6103581786155701
Loss of batch at epoch 14 : 0.5826243758201599
Loss of batch at epoch 14 : 0.6130815148353577
Loss of batch at epoch 14 : 0.5960031747817993
Loss of batch at epoch 14 : 0.594169557094574
Loss of batch at epoch 14 : 0.5672228932380676
Loss of batch at epoch 14 : 0.5753090977668762
Loss of batch at epoch 14 : 0.5243322253227234
Loss of batch at epoch 14 : 0.6032103896141052
Loss of batch at epoch 14 : 0.5836912989616394
Loss of batch at epoch 14 : 0.6061813235282898
Loss of batch at epoch 14 : 0.5966154336929321
Loss of batch at epoch 14 : 0.5864686369895935
Loss of batch at epoch 14 : 0.5901739597320557
Loss of batch at epoch 14 : 0.5724411606788635
Loss of batch at epoch 14 : 0.561993420124054
Loss of batch at epoch 14 : 0.5902431607246399
Loss of batch at epoch 14 : 0.5630407333374023
Loss of batch at epoch 14 : 0.5714187026023865
Loss of batch at epoch 14 : 0.5765352249145508
Loss of batch at epoch 14 : 0.5538014769554138
Loss of batch at epoch 14 : 0.5894870758056641
Loss of batch at epoch 14 : 0.5661367774009705
Loss of batch at epoch 14 : 0.5677240490913391
Loss of batch at epoch 14 : 0.595950186252594
Loss of batch at epoch 14 : 0.6121272444725037
Loss of batch at epoch 14 : 0.5683817267417908
Loss of batch at epoch 14 : 0.5931333303451538
Loss of batch at epoch 14 : 0.548992931842804
Loss of batch at epoch 14 : 0.5551570653915405
Loss of batch at epoch 14 : 0.5708436369895935
Loss of batch at epoch 14 : 0.6483766436576843
Loss of batch at epoch 14 : 0.5951995253562927
Loss of batch at epoch 14 : 0.5949354767799377
Loss of batch at epoch 14 : 0.5913702845573425
Loss of batch at epoch 14 : 0.6330068707466125
Loss of batch at epoch 14 : 0.5817800164222717
Loss of batch at epoch 14 : 0.5887234807014465
Average train loss of epoch 14: 0.011919748792014432
Average validation loss of epoch 14: 0.011869176068289914
Loss of batch at epoch 15 : 0.5570054650306702
Loss of batch at epoch 15 : 0.5648375153541565
Loss of batch at epoch 15 : 0.5946588516235352
Loss of batch at epoch 15 : 0.584504246711731
Loss of batch at epoch 15 : 0.5835795402526855
Loss of batch at epoch 15 : 0.5532526969909668
Loss of batch at epoch 15 : 0.5871989727020264
Loss of batch at epoch 15 : 0.57380211353302
Loss of batch at epoch 15 : 0.6224874258041382
Loss of batch at epoch 15 : 0.6155362129211426
Loss of batch at epoch 15 : 0.5743910670280457
Loss of batch at epoch 15 : 0.5925253033638
Loss of batch at epoch 15 : 0.5541155934333801
Loss of batch at epoch 15 : 0.6616784334182739
Loss of batch at epoch 15 : 0.5739828944206238
Loss of batch at epoch 15 : 0.5622439980506897
Loss of batch at epoch 15 : 0.5497667193412781
Loss of batch at epoch 15 : 0.5467253923416138
Loss of batch at epoch 15 : 0.5562344193458557
Loss of batch at epoch 15 : 0.5532921552658081
Loss of batch at epoch 15 : 0.5805203318595886
Loss of batch at epoch 15 : 0.5626339912414551
Loss of batch at epoch 15 : 0.5892801880836487
Loss of batch at epoch 15 : 0.5666353702545166
Loss of batch at epoch 15 : 0.6208771467208862
Loss of batch at epoch 15 : 0.5618550181388855
Loss of batch at epoch 15 : 0.5644238591194153
Loss of batch at epoch 15 : 0.5609229803085327
Loss of batch at epoch 15 : 0.6009064316749573
Loss of batch at epoch 15 : 0.5759381651878357
Loss of batch at epoch 15 : 0.5702748894691467
Loss of batch at epoch 15 : 0.5474153161048889
Loss of batch at epoch 15 : 0.6040281653404236
Loss of batch at epoch 15 : 0.5596009492874146
Loss of batch at epoch 15 : 0.5395277142524719
Loss of batch at epoch 15 : 0.5291203856468201
Loss of batch at epoch 15 : 0.5406941771507263
Loss of batch at epoch 15 : 0.5666223168373108
Loss of batch at epoch 15 : 0.5718387365341187
Loss of batch at epoch 15 : 0.5478499531745911
Loss of batch at epoch 15 : 0.5302148461341858
Loss of batch at epoch 15 : 0.5556410551071167
Loss of batch at epoch 15 : 0.5863302946090698
Loss of batch at epoch 15 : 0.5723487138748169
Loss of batch at epoch 15 : 0.5646470189094543
Loss of batch at epoch 15 : 0.5508210062980652
Loss of batch at epoch 15 : 0.5605167150497437
Loss of batch at epoch 15 : 0.5693891048431396
Loss of batch at epoch 15 : 0.6069301962852478
Loss of batch at epoch 15 : 0.5540903806686401
Loss of batch at epoch 15 : 0.5754326581954956
Loss of batch at epoch 15 : 0.5727081298828125
Loss of batch at epoch 15 : 0.6395619511604309
Loss of batch at epoch 15 : 0.6035861372947693
Average train loss of epoch 15: 0.011562734152328799
Average validation loss of epoch 15: 0.011662783446135345
Loss of batch at epoch 16 : 0.5795677900314331
Loss of batch at epoch 16 : 0.5693344473838806
Loss of batch at epoch 16 : 0.5887463092803955
Loss of batch at epoch 16 : 0.547160804271698
Loss of batch at epoch 16 : 0.5636003613471985
Loss of batch at epoch 16 : 0.6021673679351807
Loss of batch at epoch 16 : 0.5602036714553833
Loss of batch at epoch 16 : 0.5424742102622986
Loss of batch at epoch 16 : 0.5530800819396973
Loss of batch at epoch 16 : 0.5444958806037903
Loss of batch at epoch 16 : 0.5308480858802795
Loss of batch at epoch 16 : 0.556624174118042
Loss of batch at epoch 16 : 0.5608981251716614
Loss of batch at epoch 16 : 0.5849838852882385
Loss of batch at epoch 16 : 0.5451648831367493
Loss of batch at epoch 16 : 0.5606250762939453
Loss of batch at epoch 16 : 0.5400179624557495
Loss of batch at epoch 16 : 0.5598343014717102
Loss of batch at epoch 16 : 0.5383176207542419
Loss of batch at epoch 16 : 0.5411849021911621
Loss of batch at epoch 16 : 0.5370632410049438
Loss of batch at epoch 16 : 0.49647700786590576
Loss of batch at epoch 16 : 0.5393204689025879
Loss of batch at epoch 16 : 0.5293403267860413
Loss of batch at epoch 16 : 0.5350301861763
Loss of batch at epoch 16 : 0.5280141234397888
Loss of batch at epoch 16 : 0.5363591909408569
Loss of batch at epoch 16 : 0.537662923336029
Loss of batch at epoch 16 : 0.611007809638977
Loss of batch at epoch 16 : 0.5286073684692383
Loss of batch at epoch 16 : 0.5128426551818848
Loss of batch at epoch 16 : 0.5555236339569092
Loss of batch at epoch 16 : 0.5540412664413452
Loss of batch at epoch 16 : 0.5478456616401672
Loss of batch at epoch 16 : 0.4951363801956177
Loss of batch at epoch 16 : 0.5254048705101013
Loss of batch at epoch 16 : 0.519533097743988
Loss of batch at epoch 16 : 0.5872151851654053
Loss of batch at epoch 16 : 0.5250652432441711
Loss of batch at epoch 16 : 0.5371981263160706
Loss of batch at epoch 16 : 0.5490591526031494
Loss of batch at epoch 16 : 0.5392032265663147
Loss of batch at epoch 16 : 0.5351203680038452
Loss of batch at epoch 16 : 0.5942453145980835
Loss of batch at epoch 16 : 0.5154023170471191
Loss of batch at epoch 16 : 0.5490767955780029
Loss of batch at epoch 16 : 0.5240890979766846
Loss of batch at epoch 16 : 0.5002317428588867
Loss of batch at epoch 16 : 0.5292956829071045
Loss of batch at epoch 16 : 0.5387012958526611
Loss of batch at epoch 16 : 0.5849180817604065
Loss of batch at epoch 16 : 0.48400169610977173
Loss of batch at epoch 16 : 0.5575999617576599
Loss of batch at epoch 16 : 0.5451250672340393
Average train loss of epoch 16: 0.010998539999405602
Average validation loss of epoch 16: 0.010955168341948127
Loss of batch at epoch 17 : 0.6057615876197815
Loss of batch at epoch 17 : 0.5030009150505066
Loss of batch at epoch 17 : 0.5375532507896423
Loss of batch at epoch 17 : 0.5493834614753723
Loss of batch at epoch 17 : 0.5595505237579346
Loss of batch at epoch 17 : 0.5179038643836975
Loss of batch at epoch 17 : 0.5668463706970215
Loss of batch at epoch 17 : 0.5134506821632385
Loss of batch at epoch 17 : 0.54069983959198
Loss of batch at epoch 17 : 0.5734390020370483
Loss of batch at epoch 17 : 0.5463179349899292
Loss of batch at epoch 17 : 0.5067939162254333
Loss of batch at epoch 17 : 0.5409857034683228
Loss of batch at epoch 17 : 0.5323660969734192
Loss of batch at epoch 17 : 0.5481799244880676
Loss of batch at epoch 17 : 0.5250148773193359
Loss of batch at epoch 17 : 0.5365332365036011
Loss of batch at epoch 17 : 0.5197340250015259
Loss of batch at epoch 17 : 0.5047754049301147
Loss of batch at epoch 17 : 0.56876140832901
Loss of batch at epoch 17 : 0.5091227293014526
Loss of batch at epoch 17 : 0.5333663821220398
Loss of batch at epoch 17 : 0.5209614634513855
Loss of batch at epoch 17 : 0.5015759468078613
Loss of batch at epoch 17 : 0.5356679558753967
Loss of batch at epoch 17 : 0.5091326832771301
Loss of batch at epoch 17 : 0.5301816463470459
Loss of batch at epoch 17 : 0.5230632424354553
Loss of batch at epoch 17 : 0.5273533463478088
Loss of batch at epoch 17 : 0.4933488965034485
Loss of batch at epoch 17 : 0.49506351351737976
Loss of batch at epoch 17 : 0.508007824420929
Loss of batch at epoch 17 : 0.4967302083969116
Loss of batch at epoch 17 : 0.5103325843811035
Loss of batch at epoch 17 : 0.5679155588150024
Loss of batch at epoch 17 : 0.5665028691291809
Loss of batch at epoch 17 : 0.49784448742866516
Loss of batch at epoch 17 : 0.5542964339256287
Loss of batch at epoch 17 : 0.5043549537658691
Loss of batch at epoch 17 : 0.5784763693809509
Loss of batch at epoch 17 : 0.5786996483802795
Loss of batch at epoch 17 : 0.530446469783783
Loss of batch at epoch 17 : 0.5046093463897705
Loss of batch at epoch 17 : 0.5189627408981323
Loss of batch at epoch 17 : 0.5407220721244812
Loss of batch at epoch 17 : 0.546556830406189
Loss of batch at epoch 17 : 0.5386411547660828
Loss of batch at epoch 17 : 0.538272500038147
Loss of batch at epoch 17 : 0.5171874165534973
Loss of batch at epoch 17 : 0.5448521971702576
Loss of batch at epoch 17 : 0.5111437439918518
Loss of batch at epoch 17 : 0.5507859587669373
Loss of batch at epoch 17 : 0.5770731568336487
Loss of batch at epoch 17 : 0.582409143447876
Average train loss of epoch 17: 0.0107694971997672
Average validation loss of epoch 17: 0.01078216395394168
Loss of batch at epoch 18 : 0.5282252430915833
Loss of batch at epoch 18 : 0.49830594658851624
Loss of batch at epoch 18 : 0.5711667537689209
Loss of batch at epoch 18 : 0.5368931889533997
Loss of batch at epoch 18 : 0.525083601474762
Loss of batch at epoch 18 : 0.5062254667282104
Loss of batch at epoch 18 : 0.5402385592460632
Loss of batch at epoch 18 : 0.5412375330924988
Loss of batch at epoch 18 : 0.5578205585479736
Loss of batch at epoch 18 : 0.5221472382545471
Loss of batch at epoch 18 : 0.5059886574745178
Loss of batch at epoch 18 : 0.5686492323875427
Loss of batch at epoch 18 : 0.5258060097694397
Loss of batch at epoch 18 : 0.522502601146698
Loss of batch at epoch 18 : 0.5117431282997131
Loss of batch at epoch 18 : 0.5220621228218079
Loss of batch at epoch 18 : 0.5359197854995728
Loss of batch at epoch 18 : 0.5242392420768738
Loss of batch at epoch 18 : 0.49383801221847534
Loss of batch at epoch 18 : 0.5508174300193787
Loss of batch at epoch 18 : 0.5801528096199036
Loss of batch at epoch 18 : 0.5376427173614502
Loss of batch at epoch 18 : 0.5411449670791626
Loss of batch at epoch 18 : 0.5337945818901062
Loss of batch at epoch 18 : 0.4940970838069916
Loss of batch at epoch 18 : 0.5170689821243286
Loss of batch at epoch 18 : 0.5072352290153503
Loss of batch at epoch 18 : 0.4887870252132416
Loss of batch at epoch 18 : 0.5427234768867493
Loss of batch at epoch 18 : 0.4705282747745514
Loss of batch at epoch 18 : 0.5520243048667908
Loss of batch at epoch 18 : 0.49456986784935
Loss of batch at epoch 18 : 0.47847697138786316
Loss of batch at epoch 18 : 0.5124636888504028
Loss of batch at epoch 18 : 0.5394682884216309
Loss of batch at epoch 18 : 0.5220168828964233
Loss of batch at epoch 18 : 0.504542350769043
Loss of batch at epoch 18 : 0.5104986429214478
Loss of batch at epoch 18 : 0.5161208510398865
Loss of batch at epoch 18 : 0.5361499786376953
Loss of batch at epoch 18 : 0.49921417236328125
Loss of batch at epoch 18 : 0.47989246249198914
Loss of batch at epoch 18 : 0.47090739011764526
Loss of batch at epoch 18 : 0.49220454692840576
Loss of batch at epoch 18 : 0.5075587630271912
Loss of batch at epoch 18 : 0.5160039663314819
Loss of batch at epoch 18 : 0.5341657996177673
Loss of batch at epoch 18 : 0.5279216766357422
Loss of batch at epoch 18 : 0.5423250794410706
Loss of batch at epoch 18 : 0.48082810640335083
Loss of batch at epoch 18 : 0.46806275844573975
Loss of batch at epoch 18 : 0.5312281847000122
Loss of batch at epoch 18 : 0.4868878722190857
Loss of batch at epoch 18 : 0.5090675354003906
Average train loss of epoch 18: 0.010461049439570547
Average validation loss of epoch 18: 0.010322238459731594
Loss of batch at epoch 19 : 0.5085703730583191
Loss of batch at epoch 19 : 0.49296703934669495
Loss of batch at epoch 19 : 0.47490280866622925
Loss of batch at epoch 19 : 0.48075518012046814
Loss of batch at epoch 19 : 0.5155041813850403
Loss of batch at epoch 19 : 0.49714425206184387
Loss of batch at epoch 19 : 0.499880850315094
Loss of batch at epoch 19 : 0.5102546215057373
Loss of batch at epoch 19 : 0.47728362679481506
Loss of batch at epoch 19 : 0.5425470471382141
Loss of batch at epoch 19 : 0.4819849729537964
Loss of batch at epoch 19 : 0.49437832832336426
Loss of batch at epoch 19 : 0.5076594352722168
Loss of batch at epoch 19 : 0.46135851740837097
Loss of batch at epoch 19 : 0.49966567754745483
Loss of batch at epoch 19 : 0.5246999859809875
Loss of batch at epoch 19 : 0.5245298147201538
Loss of batch at epoch 19 : 0.5019338130950928
Loss of batch at epoch 19 : 0.5065377950668335
Loss of batch at epoch 19 : 0.4651995003223419
Loss of batch at epoch 19 : 0.4903525710105896
Loss of batch at epoch 19 : 0.4878993034362793
Loss of batch at epoch 19 : 0.4649598002433777
Loss of batch at epoch 19 : 0.5228480696678162
Loss of batch at epoch 19 : 0.5310956239700317
Loss of batch at epoch 19 : 0.5269501805305481
Loss of batch at epoch 19 : 0.46151381731033325
Loss of batch at epoch 19 : 0.5297178626060486
Loss of batch at epoch 19 : 0.5176634192466736
Loss of batch at epoch 19 : 0.51899254322052
Loss of batch at epoch 19 : 0.4895261526107788
Loss of batch at epoch 19 : 0.5373831987380981
Loss of batch at epoch 19 : 0.5268725752830505
Loss of batch at epoch 19 : 0.5291407108306885
Loss of batch at epoch 19 : 0.4877183735370636
Loss of batch at epoch 19 : 0.5469678640365601
Loss of batch at epoch 19 : 0.476168692111969
Loss of batch at epoch 19 : 0.47076615691185
Loss of batch at epoch 19 : 0.47219258546829224
Loss of batch at epoch 19 : 0.47180870175361633
Loss of batch at epoch 19 : 0.47436589002609253
Loss of batch at epoch 19 : 0.5085189342498779
Loss of batch at epoch 19 : 0.49944019317626953
Loss of batch at epoch 19 : 0.45843589305877686
Loss of batch at epoch 19 : 0.4880150854587555
Loss of batch at epoch 19 : 0.48658227920532227
Loss of batch at epoch 19 : 0.48292961716651917
Loss of batch at epoch 19 : 0.44770583510398865
Loss of batch at epoch 19 : 0.4692254066467285
Loss of batch at epoch 19 : 0.4511024057865143
Loss of batch at epoch 19 : 0.4973871111869812
Loss of batch at epoch 19 : 0.5253249406814575
Loss of batch at epoch 19 : 0.41630157828330994
Loss of batch at epoch 19 : 0.503772497177124
Average train loss of epoch 19: 0.009984093339163657
Average validation loss of epoch 19: 0.010032891424416693
Loss of batch at epoch 20 : 0.4737105071544647
Loss of batch at epoch 20 : 0.4495777487754822
Loss of batch at epoch 20 : 0.4797630310058594
Loss of batch at epoch 20 : 0.4730782210826874
Loss of batch at epoch 20 : 0.4920283555984497
Loss of batch at epoch 20 : 0.4762173593044281
Loss of batch at epoch 20 : 0.5087762475013733
Loss of batch at epoch 20 : 0.5031762719154358
Loss of batch at epoch 20 : 0.4684193730354309
Loss of batch at epoch 20 : 0.431667685508728
Loss of batch at epoch 20 : 0.5197719931602478
Loss of batch at epoch 20 : 0.4511879086494446
Loss of batch at epoch 20 : 0.44645044207572937
Loss of batch at epoch 20 : 0.4747808575630188
Loss of batch at epoch 20 : 0.46581220626831055
Loss of batch at epoch 20 : 0.45485636591911316
Loss of batch at epoch 20 : 0.48473668098449707
Loss of batch at epoch 20 : 0.5011522769927979
Loss of batch at epoch 20 : 0.4897007942199707
Loss of batch at epoch 20 : 0.49133503437042236
Loss of batch at epoch 20 : 0.5102738738059998
Loss of batch at epoch 20 : 0.5040830373764038
Loss of batch at epoch 20 : 0.4707619845867157
Loss of batch at epoch 20 : 0.43320155143737793
Loss of batch at epoch 20 : 0.5177379250526428
Loss of batch at epoch 20 : 0.48174795508384705
Loss of batch at epoch 20 : 0.5109840035438538
Loss of batch at epoch 20 : 0.5328284502029419
Loss of batch at epoch 20 : 0.48896193504333496
Loss of batch at epoch 20 : 0.4588569700717926
Loss of batch at epoch 20 : 0.5195238590240479
Loss of batch at epoch 20 : 0.4620434641838074
Loss of batch at epoch 20 : 0.5044113397598267
Loss of batch at epoch 20 : 0.45527756214141846
Loss of batch at epoch 20 : 0.44139233231544495
Loss of batch at epoch 20 : 0.46776092052459717
Loss of batch at epoch 20 : 0.44585201144218445
Loss of batch at epoch 20 : 0.49690377712249756
Loss of batch at epoch 20 : 0.48219454288482666
Loss of batch at epoch 20 : 0.4128236174583435
Loss of batch at epoch 20 : 0.4657967686653137
Loss of batch at epoch 20 : 0.5105586051940918
Loss of batch at epoch 20 : 0.4289356470108032
Loss of batch at epoch 20 : 0.4885120689868927
Loss of batch at epoch 20 : 0.481377512216568
Loss of batch at epoch 20 : 0.46376314759254456
Loss of batch at epoch 20 : 0.45014089345932007
Loss of batch at epoch 20 : 0.4682885408401489
Loss of batch at epoch 20 : 0.44813090562820435
Loss of batch at epoch 20 : 0.509395182132721
Loss of batch at epoch 20 : 0.5085471868515015
Loss of batch at epoch 20 : 0.48367804288864136
Loss of batch at epoch 20 : 0.4505043029785156
Loss of batch at epoch 20 : 0.4748379588127136
Average train loss of epoch 20: 0.00962146704903817
Average validation loss of epoch 20: 0.010011029163193623
Loss of batch at epoch 21 : 0.45045357942581177
Loss of batch at epoch 21 : 0.4196251630783081
Loss of batch at epoch 21 : 0.5023458003997803
Loss of batch at epoch 21 : 0.5154101252555847
Loss of batch at epoch 21 : 0.44144749641418457
Loss of batch at epoch 21 : 0.5020142793655396
Loss of batch at epoch 21 : 0.4727489650249481
Loss of batch at epoch 21 : 0.47760626673698425
Loss of batch at epoch 21 : 0.44015491008758545
Loss of batch at epoch 21 : 0.4723871946334839
Loss of batch at epoch 21 : 0.49482986330986023
Loss of batch at epoch 21 : 0.4313567280769348
Loss of batch at epoch 21 : 0.4504547119140625
Loss of batch at epoch 21 : 0.4557787775993347
Loss of batch at epoch 21 : 0.46671462059020996
Loss of batch at epoch 21 : 0.4583926200866699
Loss of batch at epoch 21 : 0.46507546305656433
Loss of batch at epoch 21 : 0.5390285849571228
Loss of batch at epoch 21 : 0.4281783998012543
Loss of batch at epoch 21 : 0.49010521173477173
Loss of batch at epoch 21 : 0.4669796824455261
Loss of batch at epoch 21 : 0.45743465423583984
Loss of batch at epoch 21 : 0.464558869600296
Loss of batch at epoch 21 : 0.4459155797958374
Loss of batch at epoch 21 : 0.471199631690979
Loss of batch at epoch 21 : 0.47009778022766113
Loss of batch at epoch 21 : 0.4817749857902527
Loss of batch at epoch 21 : 0.45294544100761414
Loss of batch at epoch 21 : 0.4658743143081665
Loss of batch at epoch 21 : 0.44081175327301025
Loss of batch at epoch 21 : 0.45865383744239807
Loss of batch at epoch 21 : 0.5040222406387329
Loss of batch at epoch 21 : 0.5155622959136963
Loss of batch at epoch 21 : 0.44965681433677673
Loss of batch at epoch 21 : 0.4714352488517761
Loss of batch at epoch 21 : 0.4868572950363159
Loss of batch at epoch 21 : 0.458842009305954
Loss of batch at epoch 21 : 0.4346090257167816
Loss of batch at epoch 21 : 0.4783231317996979
Loss of batch at epoch 21 : 0.49251869320869446
Loss of batch at epoch 21 : 0.430525541305542
Loss of batch at epoch 21 : 0.4821411073207855
Loss of batch at epoch 21 : 0.46038949489593506
Loss of batch at epoch 21 : 0.45966586470603943
Loss of batch at epoch 21 : 0.45463109016418457
Loss of batch at epoch 21 : 0.40739646553993225
Loss of batch at epoch 21 : 0.44762590527534485
Loss of batch at epoch 21 : 0.4278084337711334
Loss of batch at epoch 21 : 0.4670037031173706
Loss of batch at epoch 21 : 0.5002888441085815
Loss of batch at epoch 21 : 0.4993082880973816
Loss of batch at epoch 21 : 0.44965213537216187
Loss of batch at epoch 21 : 0.498836487531662
Loss of batch at epoch 21 : 0.46821698546409607
Average train loss of epoch 21: 0.00940839099385473
Average validation loss of epoch 21: 0.00959385765923394
Loss of batch at epoch 22 : 0.44898495078086853
Loss of batch at epoch 22 : 0.4359513223171234
Loss of batch at epoch 22 : 0.41814321279525757
Loss of batch at epoch 22 : 0.435459166765213
Loss of batch at epoch 22 : 0.44755905866622925
Loss of batch at epoch 22 : 0.49655842781066895
Loss of batch at epoch 22 : 0.532982349395752
Loss of batch at epoch 22 : 0.4401123523712158
Loss of batch at epoch 22 : 0.4826687276363373
Loss of batch at epoch 22 : 0.4041954576969147
Loss of batch at epoch 22 : 0.5235380530357361
Loss of batch at epoch 22 : 0.49712517857551575
Loss of batch at epoch 22 : 0.414081871509552
Loss of batch at epoch 22 : 0.4234786927700043
Loss of batch at epoch 22 : 0.44689786434173584
Loss of batch at epoch 22 : 0.456705778837204
Loss of batch at epoch 22 : 0.527876079082489
Loss of batch at epoch 22 : 0.482204794883728
Loss of batch at epoch 22 : 0.4528234601020813
Loss of batch at epoch 22 : 0.5140372514724731
Loss of batch at epoch 22 : 0.44230708479881287
Loss of batch at epoch 22 : 0.46512332558631897
Loss of batch at epoch 22 : 0.46752119064331055
Loss of batch at epoch 22 : 0.4287493824958801
Loss of batch at epoch 22 : 0.4949962794780731
Loss of batch at epoch 22 : 0.41400042176246643
Loss of batch at epoch 22 : 0.41031214594841003
Loss of batch at epoch 22 : 0.4830608069896698
Loss of batch at epoch 22 : 0.4405425786972046
Loss of batch at epoch 22 : 0.4708034098148346
Loss of batch at epoch 22 : 0.4926915466785431
Loss of batch at epoch 22 : 0.4773795008659363
Loss of batch at epoch 22 : 0.4092727303504944
Loss of batch at epoch 22 : 0.41069504618644714
Loss of batch at epoch 22 : 0.44088682532310486
Loss of batch at epoch 22 : 0.44727978110313416
Loss of batch at epoch 22 : 0.44513681530952454
Loss of batch at epoch 22 : 0.48036620020866394
Loss of batch at epoch 22 : 0.4485379159450531
Loss of batch at epoch 22 : 0.4477534592151642
Loss of batch at epoch 22 : 0.44846311211586
Loss of batch at epoch 22 : 0.49383002519607544
Loss of batch at epoch 22 : 0.4678761959075928
Loss of batch at epoch 22 : 0.464898020029068
Loss of batch at epoch 22 : 0.4787624180316925
Loss of batch at epoch 22 : 0.513378918170929
Loss of batch at epoch 22 : 0.49862799048423767
Loss of batch at epoch 22 : 0.4494897127151489
Loss of batch at epoch 22 : 0.4595484733581543
Loss of batch at epoch 22 : 0.43743547797203064
Loss of batch at epoch 22 : 0.437907874584198
Loss of batch at epoch 22 : 0.46542733907699585
Loss of batch at epoch 22 : 0.40895646810531616
Loss of batch at epoch 22 : 0.4048631191253662
Average train loss of epoch 22: 0.009233855061605852
Average validation loss of epoch 22: 0.009437159657076954
Loss of batch at epoch 23 : 0.443447470664978
Loss of batch at epoch 23 : 0.3808714747428894
Loss of batch at epoch 23 : 0.4452584385871887
Loss of batch at epoch 23 : 0.4800019860267639
Loss of batch at epoch 23 : 0.43414321541786194
Loss of batch at epoch 23 : 0.4428936243057251
Loss of batch at epoch 23 : 0.48637154698371887
Loss of batch at epoch 23 : 0.4137968420982361
Loss of batch at epoch 23 : 0.4560094177722931
Loss of batch at epoch 23 : 0.4428945779800415
Loss of batch at epoch 23 : 0.4579505920410156
Loss of batch at epoch 23 : 0.426387220621109
Loss of batch at epoch 23 : 0.46983006596565247
Loss of batch at epoch 23 : 0.47256648540496826
Loss of batch at epoch 23 : 0.4609625041484833
Loss of batch at epoch 23 : 0.4220203459262848
Loss of batch at epoch 23 : 0.41899996995925903
Loss of batch at epoch 23 : 0.48549917340278625
Loss of batch at epoch 23 : 0.42071375250816345
Loss of batch at epoch 23 : 0.44167888164520264
Loss of batch at epoch 23 : 0.4581714868545532
Loss of batch at epoch 23 : 0.49016547203063965
Loss of batch at epoch 23 : 0.45404765009880066
Loss of batch at epoch 23 : 0.4222009778022766
Loss of batch at epoch 23 : 0.4498938024044037
Loss of batch at epoch 23 : 0.4202328026294708
Loss of batch at epoch 23 : 0.43256714940071106
Loss of batch at epoch 23 : 0.4658796489238739
Loss of batch at epoch 23 : 0.42478010058403015
Loss of batch at epoch 23 : 0.46302828192710876
Loss of batch at epoch 23 : 0.41786831617355347
Loss of batch at epoch 23 : 0.4877524673938751
Loss of batch at epoch 23 : 0.38190585374832153
Loss of batch at epoch 23 : 0.5223256349563599
Loss of batch at epoch 23 : 0.39855194091796875
Loss of batch at epoch 23 : 0.4544704258441925
Loss of batch at epoch 23 : 0.5076412558555603
Loss of batch at epoch 23 : 0.4336892366409302
Loss of batch at epoch 23 : 0.4746484160423279
Loss of batch at epoch 23 : 0.5193333029747009
Loss of batch at epoch 23 : 0.427261084318161
Loss of batch at epoch 23 : 0.40308621525764465
Loss of batch at epoch 23 : 0.4376344084739685
Loss of batch at epoch 23 : 0.4413473308086395
Loss of batch at epoch 23 : 0.3978825509548187
Loss of batch at epoch 23 : 0.44949498772621155
Loss of batch at epoch 23 : 0.39474931359291077
Loss of batch at epoch 23 : 0.4545248746871948
Loss of batch at epoch 23 : 0.41429898142814636
Loss of batch at epoch 23 : 0.4114980101585388
Loss of batch at epoch 23 : 0.41391560435295105
Loss of batch at epoch 23 : 0.48172813653945923
Loss of batch at epoch 23 : 0.4788256585597992
Loss of batch at epoch 23 : 0.4487822353839874
Average train loss of epoch 23: 0.008975533249664876
Average validation loss of epoch 23: 0.009230493295072304
Loss of batch at epoch 24 : 0.4386805593967438
Loss of batch at epoch 24 : 0.46841490268707275
Loss of batch at epoch 24 : 0.4360942244529724
Loss of batch at epoch 24 : 0.49871620535850525
Loss of batch at epoch 24 : 0.39945557713508606
Loss of batch at epoch 24 : 0.44070568680763245
Loss of batch at epoch 24 : 0.4271293580532074
Loss of batch at epoch 24 : 0.453832745552063
Loss of batch at epoch 24 : 0.39369189739227295
Loss of batch at epoch 24 : 0.45384401082992554
Loss of batch at epoch 24 : 0.41508933901786804
Loss of batch at epoch 24 : 0.40128177404403687
Loss of batch at epoch 24 : 0.4363705813884735
Loss of batch at epoch 24 : 0.4209544062614441
Loss of batch at epoch 24 : 0.44466251134872437
Loss of batch at epoch 24 : 0.4036800265312195
Loss of batch at epoch 24 : 0.39177149534225464
Loss of batch at epoch 24 : 0.461832731962204
Loss of batch at epoch 24 : 0.43942081928253174
Loss of batch at epoch 24 : 0.4234521687030792
Loss of batch at epoch 24 : 0.4387216866016388
Loss of batch at epoch 24 : 0.4650980234146118
Loss of batch at epoch 24 : 0.49139872193336487
Loss of batch at epoch 24 : 0.4356062114238739
Loss of batch at epoch 24 : 0.4232650399208069
Loss of batch at epoch 24 : 0.42826077342033386
Loss of batch at epoch 24 : 0.44529083371162415
Loss of batch at epoch 24 : 0.42866241931915283
Loss of batch at epoch 24 : 0.4466390609741211
Loss of batch at epoch 24 : 0.4056297242641449
Loss of batch at epoch 24 : 0.4391160309314728
Loss of batch at epoch 24 : 0.457050621509552
Loss of batch at epoch 24 : 0.434797078371048
Loss of batch at epoch 24 : 0.46160587668418884
Loss of batch at epoch 24 : 0.4403059780597687
Loss of batch at epoch 24 : 0.44110989570617676
Loss of batch at epoch 24 : 0.4179913401603699
Loss of batch at epoch 24 : 0.4461013972759247
Loss of batch at epoch 24 : 0.41988781094551086
Loss of batch at epoch 24 : 0.4042142629623413
Loss of batch at epoch 24 : 0.3993472456932068
Loss of batch at epoch 24 : 0.40856581926345825
Loss of batch at epoch 24 : 0.41777360439300537
Loss of batch at epoch 24 : 0.4517841637134552
Loss of batch at epoch 24 : 0.5227762460708618
Loss of batch at epoch 24 : 0.413188099861145
Loss of batch at epoch 24 : 0.44699645042419434
Loss of batch at epoch 24 : 0.4453844428062439
Loss of batch at epoch 24 : 0.4392715096473694
Loss of batch at epoch 24 : 0.4444684088230133
Loss of batch at epoch 24 : 0.4369392991065979
Loss of batch at epoch 24 : 0.42181476950645447
Loss of batch at epoch 24 : 0.37756699323654175
Loss of batch at epoch 24 : 0.46499767899513245
Average train loss of epoch 24: 0.008779204541662899
Average validation loss of epoch 24: 0.009370044425681786
Loss of batch at epoch 25 : 0.42807018756866455
Loss of batch at epoch 25 : 0.43615418672561646
Loss of batch at epoch 25 : 0.39064013957977295
Loss of batch at epoch 25 : 0.3923519551753998
Loss of batch at epoch 25 : 0.45330944657325745
Loss of batch at epoch 25 : 0.404611200094223
Loss of batch at epoch 25 : 0.4128052890300751
Loss of batch at epoch 25 : 0.4279319643974304
Loss of batch at epoch 25 : 0.4147578775882721
Loss of batch at epoch 25 : 0.4342854917049408
Loss of batch at epoch 25 : 0.44077613949775696
Loss of batch at epoch 25 : 0.40771737694740295
Loss of batch at epoch 25 : 0.4276244044303894
Loss of batch at epoch 25 : 0.4308576285839081
Loss of batch at epoch 25 : 0.41074123978614807
Loss of batch at epoch 25 : 0.39447522163391113
Loss of batch at epoch 25 : 0.4777960479259491
Loss of batch at epoch 25 : 0.42266446352005005
Loss of batch at epoch 25 : 0.40541014075279236
Loss of batch at epoch 25 : 0.38917234539985657
Loss of batch at epoch 25 : 0.41942521929740906
Loss of batch at epoch 25 : 0.3979601562023163
Loss of batch at epoch 25 : 0.4272197186946869
Loss of batch at epoch 25 : 0.40827879309654236
Loss of batch at epoch 25 : 0.4574100971221924
Loss of batch at epoch 25 : 0.44949132204055786
Loss of batch at epoch 25 : 0.3973551094532013
Loss of batch at epoch 25 : 0.4174991548061371
Loss of batch at epoch 25 : 0.4016106426715851
Loss of batch at epoch 25 : 0.39112329483032227
Loss of batch at epoch 25 : 0.4240797460079193
Loss of batch at epoch 25 : 0.4567846953868866
Loss of batch at epoch 25 : 0.4249619245529175
Loss of batch at epoch 25 : 0.3864954113960266
Loss of batch at epoch 25 : 0.402090847492218
Loss of batch at epoch 25 : 0.4704837203025818
Loss of batch at epoch 25 : 0.4172017574310303
Loss of batch at epoch 25 : 0.42069944739341736
Loss of batch at epoch 25 : 0.4437906742095947
Loss of batch at epoch 25 : 0.40327537059783936
Loss of batch at epoch 25 : 0.4441082775592804
Loss of batch at epoch 25 : 0.42942681908607483
Loss of batch at epoch 25 : 0.39854398369789124
Loss of batch at epoch 25 : 0.43868929147720337
Loss of batch at epoch 25 : 0.416758269071579
Loss of batch at epoch 25 : 0.43010416626930237
Loss of batch at epoch 25 : 0.4361686408519745
Loss of batch at epoch 25 : 0.42478978633880615
Loss of batch at epoch 25 : 0.39905375242233276
Loss of batch at epoch 25 : 0.4805806577205658
Loss of batch at epoch 25 : 0.3977644443511963
Loss of batch at epoch 25 : 0.4447731375694275
Loss of batch at epoch 25 : 0.44839757680892944
Loss of batch at epoch 25 : 0.3871323764324188
Average train loss of epoch 25: 0.008512202085533455
Average validation loss of epoch 25: 0.008972787696504432

JOB STATISTICS
==============
Job ID: 5658962
Cluster: snellius
User/Group: scur0756/scur0756
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 6-12:57:52
CPU Efficiency: 76.77% of 8-12:28:12 core-walltime
Job Wall-clock time: 11:21:34
Memory Utilized: 140.85 GB
Memory Efficiency: 39.13% of 360.00 GB
